{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T13:45:10.993533Z",
     "start_time": "2024-06-10T13:45:10.989160Z"
    }
   },
   "outputs": [],
   "source": [
    "#!source /usr/local/Ascend/ascend-toolkit/set_env.sh\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from functools import partial\n",
    "from esm.modules import ContactPredictionHead, ESM1bLayerNorm, RobertaLMHead, TransformerLayer, MultiheadAttention \n",
    "import esm\n",
    "from typing import Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d99a535242f945a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T13:45:11.130618Z",
     "start_time": "2024-06-10T13:45:11.127760Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# print(f\"Number of NPU devices: {torch.npu.device_count()}\")\n",
    "# print(f\"Current NPU device index: {torch.npu.current_device()}\")\n",
    "# print(f\"NPU device name: {torch.npu.get_device_name(torch.npu.current_device())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "287e8411978aac68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T13:45:11.212788Z",
     "start_time": "2024-06-10T13:45:11.204799Z"
    }
   },
   "outputs": [],
   "source": [
    "class GroundingAttention(nn.Module):\n",
    "    def __init__(self, dim, num_heads=4, qkv_bias=True,\n",
    "                 attn_drop=0., proj_drop=0.):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = dim // num_heads\n",
    "        self.scale = head_dim**-0.5\n",
    "\n",
    "        self.kv = nn.Linear(dim, dim*2, bias=qkv_bias)\n",
    "        self.q = nn.Linear(dim, dim, bias=qkv_bias)\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        # self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "\n",
    "    def forward(self, x, r):\n",
    "        B, N, C = x.shape\n",
    "        B_, N_, C_ = r.shape\n",
    "\n",
    "        kv = self.kv(r).reshape(B_, N_, 2, self.num_heads, C_ //\n",
    "                                self.num_heads).permute(2, 0, 3, 1, 4)\n",
    "        k, v = kv.unbind(0)\n",
    "        q = self.q(x).reshape(B, N, self.num_heads, C //\n",
    "                              self.num_heads).permute(0, 2, 1, 3)\n",
    "\n",
    "        attn = (q @ k.transpose(-2, -1)) * self.scale  # (B, heads, N, N_)\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        attn = self.attn_drop(attn)\n",
    "\n",
    "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
    "        # x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f3b0ecd2235e8eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T13:45:11.271420Z",
     "start_time": "2024-06-10T13:45:11.265777Z"
    }
   },
   "outputs": [],
   "source": [
    "class FFN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(FFN, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.linear2 = nn.Linear(hidden_dim, input_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        输入 x 的形状: (batch_size, seq_len, input_dim)\n",
    "        输出 y 的形状: (batch_size, seq_len, output_dim)\n",
    "        \"\"\"\n",
    "        residual = x\n",
    "        # x = x.view(-1, x.size(-1))  # 将 x 展平成二维\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        # x = x.view(batch_size, seq_len, -1)  # 将 x 恢复成三维\n",
    "        x = residual + x\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88281771-5ee7-449a-9d52-20ee8de54c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class bertlayer(nn.Module):\n",
    "    def __init__(self, embeddingdim, hidden_dim, num_head = 16):\n",
    "        super(bertlayer, self).__init__()\n",
    "        self.atte_norm = ESM1bLayerNorm(embeddingdim)\n",
    "        self.ffn_norm = ESM1bLayerNorm(embeddingdim)\n",
    "        self.atte = torch.nn.MultiheadAttention(embed_dim = embeddingdim, num_heads = num_head, dropout = 0.0)\n",
    "        self.ffn = FFN(embeddingdim, hidden_dim)\n",
    "    def forward(self, x, x_padding_mask):\n",
    "        residual = x\n",
    "        x = self.atte_norm(x)\n",
    "        x, _ = self.atte(x, x, x, key_padding_mask = x_padding_mask)\n",
    "        x = x + residual\n",
    "        x = x + self.ffn(self.ffn_norm(x))\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "769fd10418ae2c28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T13:45:11.336232Z",
     "start_time": "2024-06-10T13:45:11.321388Z"
    }
   },
   "outputs": [],
   "source": [
    "# class InteractionBlock(nn.Module):\n",
    "#     def __init__(self, embed_dim, ffn_dim, BertLayerNorm = ESM1bLayerNorm, attention_heads = 20, add_bias_kv = True, use_rotary_embeddings = True):\n",
    "#         super(InteractionBlock, self).__init__()\n",
    "#         # self.injector_query_norm = norm_layer(embedding_dim)\n",
    "#         # self.injector_kv_norm = norm_layer(embedding_dim)\n",
    "#         # self.extractor_query_norm = norm_layer(embedding_dim)\n",
    "#         # self.extractor_kv_norm = norm_layer(embedding_dim)\n",
    "#         # self.extractor_norm = norm_layer(embedding_dim)\n",
    "#         # self.injector = GroundingAttention(embedding_dim)\n",
    "#         # self.block = GroundingAttention(embedding_dim)\n",
    "#         # self.extractor = GroundingAttention(embedding_dim)\n",
    "#         # self.extractor_ffn = FFN(embedding_dim * ffn_dim, ffn_dim_rate * embedding_dim * ffn_dim)\n",
    "#         self.attention_heads = attention_heads\n",
    "#         self.embed_dim = embed_dim\n",
    "#         self.ffn_dim = ffn_dim\n",
    "#         self.injector_q_norm = BertLayerNorm(embed_dim)\n",
    "#         self.injector_kv_norm = BertLayerNorm(embed_dim)\n",
    "#         self.injector = GroundingAttention(embed_dim)\n",
    "#         self.block = TransformerLayer(\n",
    "#             self.embed_dim,\n",
    "#             4 * self.embed_dim, # embed_dim = 1280\n",
    "#             self.attention_heads, # 20\n",
    "#             add_bias_kv=False,\n",
    "#             use_esm1b_layer_norm=True,\n",
    "#             use_rotary_embeddings=True,\n",
    "#         )\n",
    "#         self.extractor_q_norm = BertLayerNorm(embed_dim)\n",
    "#         self.extractor_kv_norm = BertLayerNorm(embed_dim)\n",
    "#         self.extractor = GroundingAttention(embed_dim)\n",
    "#         self.ffn = FFN(embed_dim, ffn_dim)\n",
    "#     def forward(self, x, r, self_attn_mask=None, self_attn_padding_mask=None, need_head_weights=False):\n",
    "#         # x = self.injector(self.injector_query_norm(x), self.injector_kv_norm(r)) + x\n",
    "#         # x = self.block(x, x)\n",
    "#         # r = self.extractor(self.extractor_query_norm(r), self.extractor_kv_norm(x)) + r\n",
    "#         # r = r + self.extractor_ffn(self.extractor_norm(r))\n",
    "#         \n",
    "#         \n",
    "#         # x, _ = self.injector_attention(\n",
    "#         #     query=self.injector_q_norm(x),\n",
    "#         #     key=self.injector_kv_norm(r),\n",
    "#         #     value=self.injector_kv_norm(r),\n",
    "#         #     key_padding_mask=self_attn_padding_mask,\n",
    "#         #     need_weights=True,\n",
    "#         #     need_head_weights=need_head_weights,\n",
    "#         #     attn_mask=self_attn_mask,\n",
    "#         # )\n",
    "#         # print(self.injector_q_norm(x).shape)\n",
    "#         # print(self.injector_q_norm(r).shape)\n",
    "#         x = x + self.injector(self.injector_q_norm(x),self.injector_kv_norm(r))\n",
    "#         x, _ = self.block(x,\n",
    "#                           self_attn_padding_mask=self_attn_padding_mask,\n",
    "#                           need_head_weights=need_head_weights,\n",
    "#                           )\n",
    "#         r = r + self.extractor(self.extractor_q_norm(r),self.extractor_kv_norm(x))\n",
    "#         r = self.ffn(r)\n",
    "#         return x, r\n",
    "class InteractionBlock(nn.Module):\n",
    "    def __init__(self, embed_dim, ffn_dim, BertLayerNorm = ESM1bLayerNorm, attention_heads = 16, add_bias_kv = True, use_rotary_embeddings = True):\n",
    "        super(InteractionBlock, self).__init__()\n",
    "        # self.injector_query_norm = norm_layer(embedding_dim)\n",
    "        # self.injector_kv_norm = norm_layer(embedding_dim)\n",
    "        # self.extractor_query_norm = norm_layer(embedding_dim)\n",
    "        # self.extractor_kv_norm = norm_layer(embedding_dim)\n",
    "        # self.extractor_norm = norm_layer(embedding_dim)\n",
    "        # self.injector = GroundingAttention(embedding_dim)\n",
    "        # self.block = GroundingAttention(embedding_dim)\n",
    "        # self.extractor = GroundingAttention(embedding_dim)\n",
    "        # self.extractor_ffn = FFN(embedding_dim * ffn_dim, ffn_dim_rate * embedding_dim * ffn_dim)\n",
    "        self.attention_heads = attention_heads\n",
    "        self.embed_dim = embed_dim\n",
    "        self.ffn_dim = ffn_dim\n",
    "        self.injector_q_norm = BertLayerNorm(embed_dim)\n",
    "        self.injector_kv_norm = BertLayerNorm(embed_dim)\n",
    "        # self.injector = GroundingAttention(embed_dim)\n",
    "\n",
    "        self.injector = torch.nn.MultiheadAttention(embed_dim = embed_dim, num_heads = attention_heads, dropout = 0.0)\n",
    "        self.block = bertlayer(embed_dim, embed_dim * 4)\n",
    "        self.extractor_q_norm = BertLayerNorm(embed_dim)\n",
    "        self.extractor_kv_norm = BertLayerNorm(embed_dim)\n",
    "        self.extractor = torch.nn.MultiheadAttention(embed_dim = embed_dim, num_heads = attention_heads, dropout = 0.0)\n",
    "        self.ffn = FFN(embed_dim, ffn_dim)\n",
    "    def forward(self, x, r, x_attn_padding_mask=None, r_attn_padding_mask = None, need_head_weights=False):\n",
    "        # x = self.injector(self.injector_query_norm(x), self.injector_kv_norm(r)) + x\n",
    "        # x = self.block(x, x)\n",
    "        # r = self.extractor(self.extractor_query_norm(r), self.extractor_kv_norm(x)) + r\n",
    "        # r = r + self.extractor_ffn(self.extractor_norm(r))\n",
    "        \n",
    "        \n",
    "        # x, _ = self.injector_attention(\n",
    "        #     query=self.injector_q_norm(x),\n",
    "        #     key=self.injector_kv_norm(r),\n",
    "        #     value=self.injector_kv_norm(r),\n",
    "        #     key_padding_mask=self_attn_padding_mask,\n",
    "        #     need_weights=True,\n",
    "        #     need_head_weights=need_head_weights,\n",
    "        #     attn_mask=self_attn_mask,\n",
    "        # )\n",
    "        # print(self.injector_q_norm(x).shape)\n",
    "        # print(self.injector_q_norm(r).shape)\n",
    "        \n",
    "        \n",
    "        # x = x + self.injector(self.injector_q_norm(x),self.injector_kv_norm(r))\n",
    "        residual_x = x\n",
    "        residual_r = r\n",
    "        # x = self.injector_q_norm(x)\n",
    "        # r = self.injector_kv_norm(r)\n",
    "        x = x.transpose(0, 1)\n",
    "        r = r.transpose(0, 1)\n",
    "        x = self.injector_q_norm(x)\n",
    "        r = self.injector_kv_norm(r)\n",
    "        # print(\"r.shape\")\n",
    "        # print(r.shape)\n",
    "        # print(\"r_attn_padding_mask.shape\")\n",
    "        # print(r_attn_padding_mask.shape)\n",
    "        # print(\"x.shape\")\n",
    "        # print(x.shape)\n",
    "        x, attn = self.injector(x, r, r, key_padding_mask=r_attn_padding_mask )\n",
    "        x = x.transpose(0, 1)\n",
    "        x = x + residual_x\n",
    "        r = residual_r\n",
    "        x = x.transpose(0, 1)\n",
    "        x = self.block(x, x_attn_padding_mask)\n",
    "        \n",
    "        # r = r + self.extractor(self.extractor_q_norm(r),self.extractor_kv_norm(x))\n",
    "        residual_r = r\n",
    "        residual_x = x.transpose(0, 1)\n",
    "        # x = self.extractor_kv_norm(x)\n",
    "        # r = self.extractor_q_norm(r)\n",
    "        # x = x.transpose(0, 1)\n",
    "        r = r.transpose(0, 1)\n",
    "        # print(r.shape)\n",
    "        # print(x.shape)\n",
    "        # print(x_attn_padding_mask.shape)\n",
    "        x = self.extractor_kv_norm(x)\n",
    "        r = self.extractor_q_norm(r)\n",
    "        r, attn = self.extractor(r, x, x, key_padding_mask=x_attn_padding_mask)\n",
    "        r = r.transpose(0, 1)\n",
    "        r = r + residual_r\n",
    "        \n",
    "        r = self.ffn(r)\n",
    "        return residual_x, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da4647de46f5d274",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T13:45:11.359130Z",
     "start_time": "2024-06-10T13:45:11.356459Z"
    }
   },
   "outputs": [],
   "source": [
    "# class part_test(nn.Module):\n",
    "#     def __init__(self, embedding_dim, ffn_dim, device, num_layers =36):\n",
    "#         super(part_test, self).__init__()\n",
    "#         self.layers = nn.ModuleList()\n",
    "#         for _ in range(num_layers):\n",
    "#             block = MultiheadAttention(\n",
    "#                     embedding_dim,\n",
    "#                     20,\n",
    "#                     add_bias_kv=False,\n",
    "#                     add_zero_attn=False,\n",
    "#                     use_rotary_embeddings=False,\n",
    "#                     encoder_decoder_attention=True\n",
    "#                 )\n",
    "#             self.layers.append(block)\n",
    "#     def forward(self, x, x_attn_padding_mask):\n",
    "#         for layer in self.layers:\n",
    "#             x, attn = layer(\n",
    "#                 query=x,\n",
    "#                 key=x,\n",
    "#                 value=x,\n",
    "#                 key_padding_mask=x_attn_padding_mask, #【[fffffttttt]】之类的\n",
    "#                 need_weights=False,\n",
    "#                 need_head_weights=False,# false\n",
    "#                 attn_mask=None, # None\n",
    "#             )\n",
    "#         return x\n",
    "# device = torch.device('npu:0')\n",
    "# modelb = part_test(1280, 1280  * 4,device)\n",
    "# X = torch.randn(30,15,1280)\n",
    "# x_attn_padding_mask = torch.zeros(15,30, dtype=torch.bool)\n",
    "# X = X.to(device)\n",
    "# x_attn_padding_mask = x_attn_padding_mask.to(device)\n",
    "# modelb.to(device)\n",
    "# opt = torch.optim.Adam(modelb.parameters(), lr=0.00001)\n",
    "# nuuu = 500000\n",
    "# for i in range(nuuu):\n",
    "#     x= modelb(X, x_attn_padding_mask)\n",
    "#     y = x.sum()\n",
    "#     y.backward()\n",
    "#     opt.step()\n",
    "#     # print(y)\n",
    "#     if i ==2:\n",
    "#         print(\"start\")\n",
    "#     if i ==nuuu - 1:\n",
    "#         print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea20878b-089b-4d1a-9efc-258ed8561984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_dim = 1280\n",
    "# modelb = TransformerLayer(\n",
    "#                 embedding_dim,\n",
    "#                 embedding_dim *4, # embed_dim = 1280\n",
    "#                 20, # 20\n",
    "#                 add_bias_kv=False,\n",
    "#                 use_esm1b_layer_norm=True,\n",
    "#                 use_rotary_embeddings=False,\n",
    "#             )\n",
    "# X = torch.randn(50,15,embedding_dim)\n",
    "# x_attn_padding_mask = torch.zeros(15,50, dtype=torch.bool)\n",
    "# X = X.to(device)\n",
    "# x_attn_padding_mask = x_attn_padding_mask.to(device)\n",
    "# modelb.to(device)\n",
    "# opt = torch_npu.optim.NpuFusedAdamW(modelb.parameters(), lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=1e-2, amsgrad=False)\n",
    "# nuuu = 5000\n",
    "# for i in range(nuuu):\n",
    "#     x, _ = modelb(X,\n",
    "#         self_attn_padding_mask=x_attn_padding_mask,\n",
    "#         need_head_weights=False,\n",
    "#     )\n",
    "#     y = x.sum()\n",
    "#     y.backward()\n",
    "#     opt.step()\n",
    "#     # print(y)\n",
    "#     if i ==2:\n",
    "#         print(\"start\")\n",
    "#     if i ==nuuu - 1:\n",
    "#         print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be7d3a5fc1b548a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T13:45:11.411293Z",
     "start_time": "2024-06-10T13:45:11.403237Z"
    }
   },
   "outputs": [],
   "source": [
    "import esm\n",
    "class DynamicFeatureSelector(nn.Module):\n",
    "    def __init__(self, input_size, num_features, num_layers=4):\n",
    "        super(DynamicFeatureSelector, self).__init__()\n",
    "        \n",
    "        # 自动计算每层的节点数量\n",
    "        self.hidden_layers = []\n",
    "        self.batch_norm_layers = []  # 用于存储 BatchNorm 层\n",
    "        current_size = input_size\n",
    "        decrement = (input_size - num_features) // num_layers  # 递减的步长\n",
    "\n",
    "        # 添加隐藏层和 BatchNorm 层\n",
    "        for _ in range(num_layers):\n",
    "            if current_size <= num_features:\n",
    "                break\n",
    "            next_size = max(current_size - decrement, num_features)\n",
    "            self.hidden_layers.append(nn.Linear(current_size, next_size))\n",
    "            self.batch_norm_layers.append(nn.BatchNorm1d(next_size))  # 添加 BatchNorm 层\n",
    "            current_size = next_size\n",
    "\n",
    "        # 将隐藏层和 BatchNorm 层转换为 ModuleList\n",
    "        self.hidden_layers = nn.ModuleList(self.hidden_layers)\n",
    "        self.batch_norm_layers = nn.ModuleList(self.batch_norm_layers)\n",
    "        self.output_layer = nn.Linear(current_size, num_features)  # 输出层\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer, batch_norm in zip(self.hidden_layers, self.batch_norm_layers):\n",
    "            x = layer(x)  # 前向传播\n",
    "            x = batch_norm(x)  # 归一化\n",
    "            x = torch.relu(x)  # 激活函数\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "class mpi_adapter(nn.Module):\n",
    "    def __init__(self, embedding_dim, ffn_dim, device, num_layers =39):\n",
    "        super(mpi_adapter, self).__init__()\n",
    "        # self.embedding = nn.Embedding(num_embeddings=22, embedding_dim=embedding_dim)\n",
    "        # self.par_position = PositionalEncoding(num_hiddens=embedding_dim, max_len = par_len)\n",
    "        # self.mut_position = PositionalEncoding(num_hiddens=embedding_dim, max_len = mut_len)\n",
    "        # self.mut_esm, _ = esm.pretrained.esm2_t33_650M_UR50D()\n",
    "        # _, self.alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
    "        # self.padding_idx = self.alphabet.padding_idx\n",
    "        self.device = device\n",
    "        # self.esm.to(self.device)\n",
    "        # self.esm.eval()\n",
    "        self.liner_mut = nn.Linear(1280,embedding_dim)\n",
    "        self.liner_par = nn.Linear(1280,embedding_dim)\n",
    "        # self.batch_converter = self.alphabet.get_batch_converter()\n",
    "        self.layers = nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            self.layers.append(InteractionBlock(embedding_dim, ffn_dim))\n",
    "    def forward(self, mut0, mut1, par, mut0_padding_mask, par_padding_mask):\n",
    "        # print([(str(0), sequence) for sequence in mut0s])\n",
    "        # print([(str(0), sequence) for sequence in mut1s])\n",
    "        # print([(str(0), sequence) for sequence in pars])\n",
    "        # _, _, mut0 = self.batch_converter([(str(0), sequence) for sequence in mut0s])\n",
    "        # _, _, mut1 = self.batch_converter([(str(0), sequence) for sequence in mut1s])\n",
    "        # _, _, par = self.batch_converter([(str(0), sequence) for sequence in pars])\n",
    "        # print(par)\n",
    "        # mut0 = mut0s.to(self.device)\n",
    "        # mut1 = mut1s.to(self.device)\n",
    "        # par = pars.to(self.device)\n",
    "        # mut0_padding_mask = mut0_padding_mask.to(self.device)\n",
    "        # par_padding_mask = par_padding_mask.to(self.device)\n",
    "        # mut0_padding_mask = mut0.eq(self.padding_idx)\n",
    "        # mut1_padding_mask = mut1.eq(self.padding_idx)\n",
    "        # par_padding_mask = par.eq(self.padding_idx)\n",
    "        # mut0_padding_mask = torch.cat((mut0_padding_mask,mut1_padding_mask),dim=1)\n",
    "        mut0 = torch.cat((mut0,mut1),dim=1)\n",
    "        mut0 = self.liner_mut(mut0)\n",
    "        par = self.liner_par(par)\n",
    "        for layer in self.layers:\n",
    "            mut0, par = layer(mut0, par, x_attn_padding_mask = mut0_padding_mask, r_attn_padding_mask = par_padding_mask)\n",
    "        return par\n",
    "    \n",
    "# device = torch.device('npu:0')\n",
    "# # modelb =  TransformerLayer(\n",
    "# #             1280,\n",
    "# #             4000, # embed_dim = 1280\n",
    "# #             20, # 20\n",
    "# #             add_bias_kv=False,\n",
    "# #             use_esm1b_layer_norm=True,\n",
    "# #             use_rotary_embeddings=False,\n",
    "# #         )\n",
    "# modelb = mpi_adapter(1280*3, 1280 * 3 * 4,device)\n",
    "# X = torch.randn(10,15,1280)\n",
    "# X2 = torch.randn(10,15,1280)\n",
    "# R = torch.randn(10,100,1280)\n",
    "# x_attn_padding_mask = torch.zeros(10,30, dtype=torch.bool)\n",
    "# R_attn_padding_mask = torch.zeros(10,100, dtype=torch.bool)\n",
    "# X = X.to(device)\n",
    "# X2 = X2.to(device)\n",
    "# R = R.to(device)\n",
    "# x_attn_padding_mask = x_attn_padding_mask.to(device)\n",
    "# R_attn_padding_mask = R_attn_padding_mask.to(device)\n",
    "# modelb.to(device)\n",
    "# opt = torch.optim.Adam(modelb.parameters(), lr=0.00001)\n",
    "# nuuu = 500000\n",
    "# for i in range(nuuu):\n",
    "#     x= modelb(X, X2, R, x_attn_padding_mask, R_attn_padding_mask)\n",
    "#     y = x.sum()\n",
    "#     y.backward()\n",
    "#     opt.step()\n",
    "#     # print(y)\n",
    "#     if i ==2:\n",
    "#         print(\"start\")\n",
    "#     if i ==nuuu - 1:\n",
    "#         print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a948d9a7-84b9-429a-b655-bdecd488cf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for layer in modelb.layers:\n",
    "#     print(next(layer.parameters()).device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d425e43-d985-4ed9-9b01-8b89035f88ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_dim = 1280*4\n",
    "# batch_size = 400\n",
    "# modelb = InteractionBlock(embedding_dim, embedding_dim * 4)\n",
    "# X = torch.randn(batch_size ,30,embedding_dim)\n",
    "# # X2 = torch.randn(batch_size ,15,embedding_dim)\n",
    "# R = torch.randn(batch_size ,100,embedding_dim)\n",
    "# x_attn_padding_mask = torch.zeros(batch_size ,30, dtype=torch.bool)\n",
    "# R_attn_padding_mask = torch.zeros(batch_size ,100, dtype=torch.bool)\n",
    "# X = X.to(device)\n",
    "# # X2 = X2.to(device)\n",
    "# R = R.to(device)\n",
    "# x_attn_padding_mask = x_attn_padding_mask.to(device)\n",
    "# R_attn_padding_mask = R_attn_padding_mask.to(device)\n",
    "# modelb.to(device)\n",
    "# opt = torch.optim.Adam(modelb.parameters(), lr=0.00001)\n",
    "# nuuu = 500000\n",
    "# for i in range(nuuu):\n",
    "#     x , _= modelb(X, R, x_attn_padding_mask, R_attn_padding_mask)\n",
    "#     y = x.sum()\n",
    "#     y.backward()\n",
    "#     opt.step()\n",
    "#     if i ==2:\n",
    "#         print(\"start\")\n",
    "#     if i ==nuuu - 1:\n",
    "#         print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54e341f1f47d3180",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T13:45:11.439194Z",
     "start_time": "2024-06-10T13:45:11.434447Z"
    }
   },
   "outputs": [],
   "source": [
    "class MLP_head(nn.Module):\n",
    "    def __init__(self, embedding_dim, num_layers = 2):\n",
    "        super(MLP_head, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            self.layers.append(GroundingAttention(embedding_dim))\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, x)\n",
    "        return x[:, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd8d5415476c250c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T13:45:11.474135Z",
     "start_time": "2024-06-10T13:45:11.471531Z"
    }
   },
   "outputs": [],
   "source": [
    "class MLP_head_one_layer(nn.Module):\n",
    "    def __init__(self, embedding_dim, device, num_layers = 1,attention_heads = 16):\n",
    "        super(MLP_head_one_layer, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.device = device\n",
    "        self.attention = torch.nn.MultiheadAttention(embed_dim = embedding_dim, num_heads = attention_heads, dropout = 0.0)\n",
    "        # for _ in range(num_layers):\n",
    "        #     self.layers.append(TransformerLayer(\n",
    "        #         embedding_dim,\n",
    "        #         4 * embedding_dim, # embed_dim = 1280\n",
    "        #         attention_heads, # 20\n",
    "        #         add_bias_kv=False,\n",
    "        #         use_esm1b_layer_norm=True,\n",
    "        #         use_rotary_embeddings=True,\n",
    "        #         ))\n",
    "    def forward(self, x, x_attn_padding_mask, need_head_weights=False):\n",
    "        x_attn_padding_mask = x_attn_padding_mask.to(self.device)\n",
    "        result = x[:, 0:1, :]\n",
    "        x = x.transpose(0, 1)\n",
    "        result = result.transpose(0, 1)\n",
    "        result, attn = self.attention(result, x, x, key_padding_mask = x_attn_padding_mask)\n",
    "        # for layer in self.layers:\n",
    "        #     x = x.transpose(0, 1)\n",
    "        #     x, _ = layer(x,\n",
    "        #                 self_attn_padding_mask=x_attn_padding_mask,\n",
    "        #                 need_head_weights=need_head_weights,\n",
    "        #                 )\n",
    "        #     x = x.transpose(0, 1)\n",
    "        result = result.transpose(0, 1)\n",
    "        result = result.squeeze(1)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14f475c09191b81a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T13:45:11.513230Z",
     "start_time": "2024-06-10T13:45:11.506687Z"
    }
   },
   "outputs": [],
   "source": [
    "#bert中的带权交叉熵顺势函数\n",
    "class cross_entropy_bert(nn.Module):\n",
    "    def __init__(self, device):\n",
    "        super(cross_entropy_bert, self).__init__()\n",
    "        # self.liner = nn.Linear(embedding_dim, 4)\n",
    "        self.activate = nn.Sigmoid()\n",
    "        self.device = device\n",
    "    def forward(self, b_labels, outputs, weights):\n",
    "        # weights = weights\n",
    "        # outputs = self.liner(outputs)\n",
    "        # print(\"output:\")\n",
    "        # print(outputs)\n",
    "        # outputs = self.activate(outputs)\n",
    "        labels = []\n",
    "        for index, fue in enumerate(b_labels):\n",
    "            labels.append(fue)\n",
    "        loss_sum = torch.tensor(0)\n",
    "        for i in range(outputs.shape[0]):\n",
    "            back_part = torch.tensor(0).to(device)\n",
    "            for j in outputs[i]:\n",
    "                back_part = back_part + torch.exp(j).to(device)\n",
    "            back_part = torch.log(back_part).to(device)\n",
    "            loss_sum = weights[labels[i]] * ((-1) * outputs[i][labels[i]] + back_part)\n",
    "        loss_sum = loss_sum/outputs.shape[0]\n",
    "        return loss_sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e77a21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, in_channels, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels, in_channels, kernel_size=3, padding=1)\n",
    "        # Using average pooling instead\n",
    "        self.pool = nn.MaxPool1d(kernel_size=1, stride=1)  # Keep dimensions the same\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x  # Save input for the skip connection\n",
    "        out = self.conv1(x)\n",
    "        out = nn.ReLU()(out)\n",
    "        out = self.conv2(out)\n",
    "        out = nn.ReLU()(out)\n",
    "        out = self.pool(out)  # Apply pooling, maintaining dimensions\n",
    "        out += identity  # Skip connection\n",
    "        return out\n",
    "\n",
    "class ResidualModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(ResidualModel, self).__init__()\n",
    "        self.residual_block1 = ResidualBlock(input_dim)\n",
    "        self.residual_block2 = ResidualBlock(input_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.residual_block1(x)\n",
    "        x = self.residual_block2(x)\n",
    "        return x \n",
    "\n",
    "class Conv1DGlobalAveragePoolingModel(nn.Module):\n",
    "    def __init__(self, embedding_dim):\n",
    "        super(Conv1DGlobalAveragePoolingModel, self).__init__()\n",
    "        self.conv1d = nn.Conv1d(embedding_dim, embedding_dim, kernel_size=3, padding=1)  # 使用现成的卷积层\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool1d(1)  # 全局平均池化\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x 的形状为 (batch_size, length, embedding_dim)\n",
    "        x = x.transpose(1, 2)  # 调整维度为 (batch_size, embedding_dim, length)\n",
    "        x = self.conv1d(x)  # 经过一维卷积层\n",
    "        x = self.global_avg_pool(x)  # 经过全局平均池化\n",
    "        return x  # 输出的形状为 (batch_size, embedding_dim, 1)\n",
    "\n",
    "\n",
    "class mippi_one(nn.Module):\n",
    "    def __init__(self, embedding_dim, ffn_dim, device, num_layers =3):\n",
    "        super(mippi_one, self).__init__()\n",
    "        # self.embedding = nn.Embedding(num_embeddings=22, embedding_dim=embedding_dim)\n",
    "        # self.par_position = PositionalEncoding(num_hiddens=embedding_dim, max_len = par_len)\n",
    "        # self.mut_position = PositionalEncoding(num_hiddens=embedding_dim, max_len = mut_len)\n",
    "        # self.mut_esm, _ = esm.pretrained.esm2_t33_650M_UR50D()\n",
    "        # _, self.alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
    "        # self.padding_idx = self.alphabet.padding_idx\n",
    "        self.device = device\n",
    "        # self.esm.to(self.device)\n",
    "        # self.esm.eval()\n",
    "        self.liner_mut = nn.Linear(1280,embedding_dim)\n",
    "        self.liner_par = nn.Linear(1280,embedding_dim)\n",
    "        # self.batch_converter = self.alphabet.get_batch_converter()\n",
    "        self.layersa = nn.ModuleList()\n",
    "        self.layersb = nn.ModuleList()\n",
    "        for _ in range(3):\n",
    "            self.layersa.append(bertlayer(embedding_dim, embedding_dim * 4))\n",
    "            self.layersa.append(bertlayer(embedding_dim, embedding_dim * 4))\n",
    "        self.conv1 = ResidualModel(embedding_dim)\n",
    "        self.conv2 = ResidualModel(embedding_dim)\n",
    "        self.conv3 = ResidualModel(embedding_dim)\n",
    "        self.conv4 = ResidualModel(embedding_dim)\n",
    "        self.pooling = Conv1DGlobalAveragePoolingModel(embedding_dim)\n",
    "\n",
    "    def forward(self, mut0, mut1, par, mut0_padding_mask, mut1_padding_mask, par_padding_mask):\n",
    "        # print([(str(0), sequence) for sequence in mut0s])\n",
    "        # print([(str(0), sequence) for sequence in mut1s])\n",
    "        # print([(str(0), sequence) for sequence in pars])\n",
    "        # _, _, mut0 = self.batch_converter([(str(0), sequence) for sequence in mut0s])\n",
    "        # _, _, mut1 = self.batch_converter([(str(0), sequence) for sequence in mut1s])\n",
    "        # _, _, par = self.batch_converter([(str(0), sequence) for sequence in pars])\n",
    "        # print(par)\n",
    "        # mut0 = mut0s.to(self.device)\n",
    "        # mut1 = mut1s.to(self.device)\n",
    "        # par = pars.to(self.device)\n",
    "        # mut0_padding_mask = mut0_padding_mask.to(self.device)\n",
    "        # par_padding_mask = par_padding_mask.to(self.device)\n",
    "        # mut0_padding_mask = mut0.eq(self.padding_idx)\n",
    "        # mut1_padding_mask = mut1.eq(self.padding_idx)\n",
    "        # par_padding_mask = par.eq(self.padding_idx)\n",
    "        # mut0_padding_mask = torch.cat((mut0_padding_mask,mut1_padding_mask),dim=1)\n",
    "        # mut0 = torch.cat((mut0,mut1),dim=1)\n",
    "        mut0 = self.liner_mut(mut0)\n",
    "        mut1 = self.liner_mut(mut1)\n",
    "        par = self.liner_par(par)\n",
    "        mut0 = mut0.transpose(0,1)\n",
    "        mut1 = mut1.transpose(0,1)\n",
    "        par = par.transpose(0,1)\n",
    "        for layer in self.layersa:\n",
    "            mut0 = layer(mut0, mut0_padding_mask)\n",
    "            mut1 = layer(mut1, mut1_padding_mask)\n",
    "        for layer in self.layersb:\n",
    "            par = layer(par, par_padding_mask)\n",
    "        mut0 = mut0.transpose(0,1)\n",
    "        mut1 = mut1.transpose(0,1)\n",
    "        par = par.transpose(0,1)\n",
    "        mut0 = mut0.transpose(2,1)\n",
    "        mut1 = mut1.transpose(2,1)\n",
    "        par = par.transpose(2,1)\n",
    "        mut0 = self.conv1(mut0)\n",
    "        mut1 = self.conv1(mut1)\n",
    "        par = self.conv2(par)\n",
    "        par = self.conv3(par)\n",
    "        mut0 = mut0.transpose(2,1)\n",
    "        mut1 = mut1.transpose(2,1)\n",
    "        par = par.transpose(2,1)\n",
    "        par = torch.cat((mut0 / mut1, mut0 - mut1, par, mut0, mut1), dim = 1)\n",
    "        return self.pooling(par).squeeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5e8fd6a6884286d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T13:45:11.547641Z",
     "start_time": "2024-06-10T13:45:11.542467Z"
    }
   },
   "outputs": [],
   "source": [
    "class Sum_model(nn.Module):\n",
    "    def __init__(self, device, embedding_dim = 192,):\n",
    "        super(Sum_model, self).__init__()\n",
    "        self.device = device\n",
    "        self.result = nn.Parameter(torch.randn(1280))\n",
    "        self.backbone = mippi_one(embedding_dim, embedding_dim*4,device)\n",
    "        # self.neck = MLP_head_one_layer(embedding_dim, device)\n",
    "        # self.head = cross_entropy_bert(embedding_dim, device)\n",
    "        self.head = nn.Linear(embedding_dim, 4)\n",
    "    def forward(self,  mut0s, mut1s, pars, mut0_padding_mask, mut1_padding_mask, par_padding_mask, weight, label):\n",
    "        res = self.result.repeat(pars.shape[0], 1).unsqueeze(1) \n",
    "        pars = torch.concat([res,pars], dim = 1)\n",
    "        false_column = torch.zeros(par_padding_mask.size(0), 1, dtype=torch.bool).to(self.device)\n",
    "        # 在第一列前添加一排 False\n",
    "        par_padding_mask = torch.cat((false_column, par_padding_mask), dim=1)\n",
    "        x = self.backbone(mut0s, mut1s, pars, mut0_padding_mask, mut1_padding_mask, par_padding_mask)\n",
    "        # print(\"x1:\")\n",
    "        # x = self.neck(pars, par_padding_mask)\n",
    "        # x = self.neck(x, par_padding_mask)\n",
    "        # print(\"x2\")\n",
    "        # print(x)\n",
    "        # x = self.head(label, x, weight)\n",
    "        x = self.head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4184a5a3bdf4eaef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T13:45:11.592148Z",
     "start_time": "2024-06-10T13:45:11.586592Z"
    }
   },
   "outputs": [],
   "source": [
    "class PandasDataReader:\n",
    "    def __init__(self, df, batch_size=1, shuffle=False):\n",
    "        self.df = df.sample(frac=1).reset_index(drop=True) if shuffle else df\n",
    "        self.batch_size = batch_size\n",
    "        self.current_index = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.current_index >= len(self.df):\n",
    "            raise StopIteration()\n",
    "\n",
    "        batch = self.df.iloc[self.current_index:self.current_index+self.batch_size]\n",
    "        self.current_index += self.batch_size\n",
    "\n",
    "        # 如果 batch_size 为 1, 则直接返回 batch 的第一行\n",
    "        return batch.iloc[0] if self.batch_size == 1 else batch\n",
    "# data_reader = PandasDataReader(df, batch_size=7, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a82882c-9e80-4015-8b7b-f86dba99773d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T13:45:11.633730Z",
     "start_time": "2024-06-10T13:45:11.625740Z"
    }
   },
   "outputs": [],
   "source": [
    "class ESMModelWrapper(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(ESMModelWrapper, self).__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, batch_tokens, repr_layers=[33], return_contacts=False):\n",
    "        return self.model(batch_tokens, repr_layers=repr_layers, return_contacts=return_contacts)\n",
    "\n",
    "\n",
    "class ESMFeatureEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ESMFeatureEncoder, self).__init__()\n",
    "        self.device = 'cuda:3'\n",
    "        self.model, self.alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()  # Set the model to evaluation mode\n",
    "        self.batch_converter = self.alphabet.get_batch_converter()\n",
    "        self.padding_idx = self.alphabet.padding_idx\n",
    "        # Wrap the model with the ESMModelWrapper\n",
    "        self.model = ESMModelWrapper(self.model)\n",
    "\n",
    "    def encode(self, sequences):\n",
    "        batch_labels, batch_strs, batch_tokens = self.batch_converter([(str(0), sequence) for sequence in sequences])\n",
    "        batch_tokens = batch_tokens.to(self.device)\n",
    "        batch_mask = batch_tokens.eq(self.padding_idx)\n",
    "        # print(batch_tokens.shape)\n",
    "        with torch.no_grad():\n",
    "            results = self.model(batch_tokens, repr_layers=[33], return_contacts=False)\n",
    "        token_representations = results['representations'][33]\n",
    "        # print(results['representations'][33].mean(dim=1).unsqueeze(1).shape)\n",
    "        return token_representations,batch_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fdf89b-5dff-4b16-a83c-c48b526df38d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0078ee5039c96a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T13:45:12.184538Z",
     "start_time": "2024-06-10T13:45:11.673111Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38706, 26)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#Feature AC</th>\n",
       "      <th>Feature range(s)</th>\n",
       "      <th>Original sequence</th>\n",
       "      <th>Resulting sequence</th>\n",
       "      <th>Feature short label</th>\n",
       "      <th>Feature type</th>\n",
       "      <th>Feature annotation</th>\n",
       "      <th>Affected protein AC</th>\n",
       "      <th>Affected protein symbol</th>\n",
       "      <th>Affected protein full name</th>\n",
       "      <th>...</th>\n",
       "      <th>n_partner</th>\n",
       "      <th>mutAC</th>\n",
       "      <th>mut0</th>\n",
       "      <th>parAC</th>\n",
       "      <th>par0</th>\n",
       "      <th>mut1</th>\n",
       "      <th>label</th>\n",
       "      <th>mutAC1</th>\n",
       "      <th>position_total</th>\n",
       "      <th>position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EBI-10039489</td>\n",
       "      <td>[81-81]</td>\n",
       "      <td>[V]</td>\n",
       "      <td>[E]</td>\n",
       "      <td>p.Val81Glu</td>\n",
       "      <td>mutation disrupting(MI:0573)</td>\n",
       "      <td></td>\n",
       "      <td>P28795</td>\n",
       "      <td>PEX3</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>P28795</td>\n",
       "      <td>MAPNQRSRSLLQRHRGKVLISLTGIAALFTTGSVVVFFVKRWLYKQ...</td>\n",
       "      <td>Q03694</td>\n",
       "      <td>MVLSRGETKKNSVRLTAKQEKKPQSTFQTLKQSLKLSNNKKLKQDS...</td>\n",
       "      <td>MAPNQRSRSLLQRHRGKVLISLTGIAALFTTGSVVVFFVKRWLYKQ...</td>\n",
       "      <td>0</td>\n",
       "      <td>P28795_Val81Glu</td>\n",
       "      <td>[81]</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EBI-10039495</td>\n",
       "      <td>[188-188]</td>\n",
       "      <td>[N]</td>\n",
       "      <td>[I]</td>\n",
       "      <td>p.Asn188Ile</td>\n",
       "      <td>mutation decreasing(MI:0119)</td>\n",
       "      <td></td>\n",
       "      <td>P28795</td>\n",
       "      <td>PEX3</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>P28795</td>\n",
       "      <td>MAPNQRSRSLLQRHRGKVLISLTGIAALFTTGSVVVFFVKRWLYKQ...</td>\n",
       "      <td>Q03694</td>\n",
       "      <td>MVLSRGETKKNSVRLTAKQEKKPQSTFQTLKQSLKLSNNKKLKQDS...</td>\n",
       "      <td>MAPNQRSRSLLQRHRGKVLISLTGIAALFTTGSVVVFFVKRWLYKQ...</td>\n",
       "      <td>1</td>\n",
       "      <td>P28795_Asn188Ile</td>\n",
       "      <td>[188]</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EBI-10039551</td>\n",
       "      <td>[81-81]</td>\n",
       "      <td>[V]</td>\n",
       "      <td>[E]</td>\n",
       "      <td>p.Val81Glu</td>\n",
       "      <td>mutation disrupting(MI:0573)</td>\n",
       "      <td></td>\n",
       "      <td>P28795</td>\n",
       "      <td>PEX3</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>P28795</td>\n",
       "      <td>MAPNQRSRSLLQRHRGKVLISLTGIAALFTTGSVVVFFVKRWLYKQ...</td>\n",
       "      <td>Q03694</td>\n",
       "      <td>MVLSRGETKKNSVRLTAKQEKKPQSTFQTLKQSLKLSNNKKLKQDS...</td>\n",
       "      <td>MAPNQRSRSLLQRHRGKVLISLTGIAALFTTGSVVVFFVKRWLYKQ...</td>\n",
       "      <td>0</td>\n",
       "      <td>P28795_Val81Glu</td>\n",
       "      <td>[81]</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EBI-10039706</td>\n",
       "      <td>[81-81]</td>\n",
       "      <td>[V]</td>\n",
       "      <td>[E]</td>\n",
       "      <td>p.Val81Glu</td>\n",
       "      <td>mutation disrupting(MI:0573)</td>\n",
       "      <td></td>\n",
       "      <td>P28795</td>\n",
       "      <td>PEX3</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>P28795</td>\n",
       "      <td>MAPNQRSRSLLQRHRGKVLISLTGIAALFTTGSVVVFFVKRWLYKQ...</td>\n",
       "      <td>Q03694</td>\n",
       "      <td>MVLSRGETKKNSVRLTAKQEKKPQSTFQTLKQSLKLSNNKKLKQDS...</td>\n",
       "      <td>MAPNQRSRSLLQRHRGKVLISLTGIAALFTTGSVVVFFVKRWLYKQ...</td>\n",
       "      <td>0</td>\n",
       "      <td>P28795_Val81Glu</td>\n",
       "      <td>[81]</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EBI-10039722</td>\n",
       "      <td>[81-81]</td>\n",
       "      <td>[V]</td>\n",
       "      <td>[E]</td>\n",
       "      <td>p.Val81Glu</td>\n",
       "      <td>mutation disrupting(MI:0573)</td>\n",
       "      <td></td>\n",
       "      <td>P28795</td>\n",
       "      <td>PEX3</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>P28795</td>\n",
       "      <td>MAPNQRSRSLLQRHRGKVLISLTGIAALFTTGSVVVFFVKRWLYKQ...</td>\n",
       "      <td>Q03694</td>\n",
       "      <td>MVLSRGETKKNSVRLTAKQEKKPQSTFQTLKQSLKLSNNKKLKQDS...</td>\n",
       "      <td>MAPNQRSRSLLQRHRGKVLISLTGIAALFTTGSVVVFFVKRWLYKQ...</td>\n",
       "      <td>0</td>\n",
       "      <td>P28795_Val81Glu</td>\n",
       "      <td>[81]</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    #Feature AC Feature range(s) Original sequence Resulting sequence  \\\n",
       "0  EBI-10039489          [81-81]               [V]                [E]   \n",
       "1  EBI-10039495        [188-188]               [N]                [I]   \n",
       "2  EBI-10039551          [81-81]               [V]                [E]   \n",
       "3  EBI-10039706          [81-81]               [V]                [E]   \n",
       "4  EBI-10039722          [81-81]               [V]                [E]   \n",
       "\n",
       "  Feature short label                  Feature type Feature annotation  \\\n",
       "0          p.Val81Glu  mutation disrupting(MI:0573)                      \n",
       "1         p.Asn188Ile  mutation decreasing(MI:0119)                      \n",
       "2          p.Val81Glu  mutation disrupting(MI:0573)                      \n",
       "3          p.Val81Glu  mutation disrupting(MI:0573)                      \n",
       "4          p.Val81Glu  mutation disrupting(MI:0573)                      \n",
       "\n",
       "  Affected protein AC Affected protein symbol Affected protein full name  ...  \\\n",
       "0              P28795                    PEX3                             ...   \n",
       "1              P28795                    PEX3                             ...   \n",
       "2              P28795                    PEX3                             ...   \n",
       "3              P28795                    PEX3                             ...   \n",
       "4              P28795                    PEX3                             ...   \n",
       "\n",
       "  n_partner   mutAC                                               mut0  \\\n",
       "0         2  P28795  MAPNQRSRSLLQRHRGKVLISLTGIAALFTTGSVVVFFVKRWLYKQ...   \n",
       "1         2  P28795  MAPNQRSRSLLQRHRGKVLISLTGIAALFTTGSVVVFFVKRWLYKQ...   \n",
       "2         2  P28795  MAPNQRSRSLLQRHRGKVLISLTGIAALFTTGSVVVFFVKRWLYKQ...   \n",
       "3         2  P28795  MAPNQRSRSLLQRHRGKVLISLTGIAALFTTGSVVVFFVKRWLYKQ...   \n",
       "4         2  P28795  MAPNQRSRSLLQRHRGKVLISLTGIAALFTTGSVVVFFVKRWLYKQ...   \n",
       "\n",
       "    parAC                                               par0  \\\n",
       "0  Q03694  MVLSRGETKKNSVRLTAKQEKKPQSTFQTLKQSLKLSNNKKLKQDS...   \n",
       "1  Q03694  MVLSRGETKKNSVRLTAKQEKKPQSTFQTLKQSLKLSNNKKLKQDS...   \n",
       "2  Q03694  MVLSRGETKKNSVRLTAKQEKKPQSTFQTLKQSLKLSNNKKLKQDS...   \n",
       "3  Q03694  MVLSRGETKKNSVRLTAKQEKKPQSTFQTLKQSLKLSNNKKLKQDS...   \n",
       "4  Q03694  MVLSRGETKKNSVRLTAKQEKKPQSTFQTLKQSLKLSNNKKLKQDS...   \n",
       "\n",
       "                                                mut1  label            mutAC1  \\\n",
       "0  MAPNQRSRSLLQRHRGKVLISLTGIAALFTTGSVVVFFVKRWLYKQ...      0   P28795_Val81Glu   \n",
       "1  MAPNQRSRSLLQRHRGKVLISLTGIAALFTTGSVVVFFVKRWLYKQ...      1  P28795_Asn188Ile   \n",
       "2  MAPNQRSRSLLQRHRGKVLISLTGIAALFTTGSVVVFFVKRWLYKQ...      0   P28795_Val81Glu   \n",
       "3  MAPNQRSRSLLQRHRGKVLISLTGIAALFTTGSVVVFFVKRWLYKQ...      0   P28795_Val81Glu   \n",
       "4  MAPNQRSRSLLQRHRGKVLISLTGIAALFTTGSVVVFFVKRWLYKQ...      0   P28795_Val81Glu   \n",
       "\n",
       "  position_total position  \n",
       "0           [81]       81  \n",
       "1          [188]      188  \n",
       "2           [81]       81  \n",
       "3           [81]       81  \n",
       "4           [81]       81  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_path = 'mippi/processed_mutations.dataset'\n",
    "df = pd.read_pickle(data_path)\n",
    "\n",
    "new_df1 = df[df['label'] == 1].copy()\n",
    "new_df1['mut0'], new_df1['mut1'] = new_df1['mut1'], new_df1['mut0']\n",
    "new_df1['label'] = 3\n",
    "new_df2 = df[df['label'] == 3].copy()\n",
    "new_df2['mut0'], new_df2['mut1'] = new_df2['mut1'], new_df2['mut0']\n",
    "new_df2['label'] = 1\n",
    "\n",
    "new_df3 = df[df['label'] == 2].copy()\n",
    "new_df3['mut0'], new_df3['mut1'] = new_df3['mut1'], new_df3['mut0']\n",
    "new_df3['label'] = 2\n",
    "df = pd.concat([df, new_df2, new_df1, new_df3], ignore_index=True)\n",
    "df[\"position_total\"] = df[\"Feature range(s)\"].apply(\n",
    "    lambda x: sorted(set([int(y.split(\"-\")[0]) for y in x] + [int(y.split(\"-\")[1]) for y in x]))\n",
    ")\n",
    "df[\"position\"] = df[\"position_total\"].apply(lambda x: math.ceil((min(x) + max(x)) / 2))\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2e4a2fc82b6203",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T13:45:12.227042Z",
     "start_time": "2024-06-10T13:45:12.186618Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37276, 26)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_half_protein_used =10 \n",
    "# seq_lengths = df['Original sequence'].apply(lambda x: len(x[0]))\n",
    "# # 选择唯一元素长度小于等于 10 的行\n",
    "# df_filtered = df.loc[seq_lengths <= len_half_protein_used]\n",
    "# seq_lengths = df['Resulting sequence'].apply(lambda x: len(x[0]))\n",
    "# # 选择唯一元素长度小于等于 10 的行\n",
    "# df_filtered = df.loc[seq_lengths <= len_half_protein_used]\n",
    "df = df[df[\"position_total\"].apply(lambda x: max(x) - min(x) < 2* len_half_protein_used)]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cbeee234e73fb2e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T13:45:12.249871Z",
     "start_time": "2024-06-10T13:45:12.228919Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29082, 26)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['mut0'].str.len() <= 1000]\n",
    "df = df[df['par0'].str.len() <= 1000]\n",
    "df = df[df['label'] != 4]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9640a559-cd38-4338-9160-c0d1779f2e71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T13:45:12.255684Z",
     "start_time": "2024-06-10T13:45:12.252646Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "class GHMC_Loss(nn.Module):\n",
    "    def __init__(self, device, bins=8, momentum=0.3):\n",
    "        super(GHMC_Loss, self).__init__()\n",
    "        self.device = device\n",
    "        self.bins = bins\n",
    "        self.momentum = momentum\n",
    "        self.edges = [float(x) / self.bins for x in range(self.bins + 1)]\n",
    "        if momentum > 0:\n",
    "            self.acc_sum = np.zeros(bins)\n",
    "\n",
    "    def forward(self, targets, logits, no_meaning):\n",
    "        targets = torch.tensor(targets.to_list())\n",
    "        targets = F.one_hot(targets, num_classes=4).float().to(self.device)\n",
    "        # Calculate gradient norm\n",
    "        edges = self.edges\n",
    "        mmt = self.momentum\n",
    "        weights = torch.zeros_like(logits)\n",
    "        g = torch.abs(logits.softmax(dim=1).detach().to(self.device) - targets.to(self.device))\n",
    "\n",
    "        tot = logits.shape[0] * logits.shape[1]  # Total number of elements\n",
    "        n = 0  # n valid bins\n",
    "        for i in range(self.bins):\n",
    "            inds = (g >= edges[i]) & (g < edges[i + 1])\n",
    "            num_in_bin = inds.sum().item()\n",
    "            if num_in_bin > 0:\n",
    "                if mmt > 0:\n",
    "                    self.acc_sum[i] = mmt * self.acc_sum[i] + (1 - mmt) * num_in_bin\n",
    "                    weights[inds] = tot / self.acc_sum[i]\n",
    "                else:\n",
    "                    weights[inds] = tot / num_in_bin\n",
    "                n += 1\n",
    "        if n > 0:\n",
    "            weights = weights / n\n",
    "\n",
    "        # Flatten targets to match logits shape\n",
    "        targets = targets.argmax(dim=1)\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = F.cross_entropy(logits, targets, reduction='none')\n",
    "\n",
    "        # Apply weights to the loss\n",
    "        weights = weights.max(dim=1)[0]  # Get the maximum weight for each sample\n",
    "        loss = (loss * weights).sum() / tot\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e4c624c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(max_len, d_model):\n",
    "    # 创建位置编码矩阵\n",
    "    position = torch.arange(max_len, dtype=torch.float).unsqueeze(1)  # 形状为 (max_len, 1)\n",
    "    div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(np.log(10000.0) / d_model))  # 计算分母\n",
    "    \n",
    "    # 计算位置编码\n",
    "    pe = torch.zeros(max_len, d_model)  # 初始化位置编码矩阵\n",
    "    pe[:, 0::2] = torch.sin(position * div_term)  # 偶数维度\n",
    "    pe[:, 1::2] = torch.cos(position * div_term)  # 奇数维度\n",
    "    pe.requires_grad = False\n",
    "    return pe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9e986a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [987/26174], Loss: 0.33121582865715027\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "from sklearn.metrics import accuracy_score\n",
    "import json\n",
    "batch_size = 4\n",
    "# 五折交叉验证\n",
    "splits = 10\n",
    "# Create StratifiedKFold object.\n",
    "# 创建StratifiedKFold对象    StratifiedKFold是sklearn库中的一个类，用于将数据集进行分层抽样设置了4个分割（n_splits=splits），打乱数据顺序（shuffle=True）并设置随机种子（random_state=1）。\n",
    "skf = StratifiedKFold(n_splits=splits, shuffle=True)# , random_state=1\n",
    "# device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device('cuda:3')\n",
    "# 定义优化器\n",
    "model = Sum_model(device)\n",
    "model.load_state_dict(torch.load('model_params_mirror2.pth'))\n",
    "print(f\"Using device: {device}\")\n",
    "model.to(device)\n",
    "model_loss = GHMC_Loss(device)\n",
    "esm_model = ESMFeatureEncoder()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=4e-6, betas=(0.9, 0.999), weight_decay=1e-6, amsgrad=False)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=6e-5)\n",
    "# for train_index, test_index in skf.split(df,df[\"label\"]):#它接受两个参数：x 和 y，分别表示特征数据和目标数据\n",
    "#     x_train_fold, x_test_fold = df.iloc[train_index], df.iloc[test_index]#iloc是pandas库中的一个属性，用于基于整数位置的索引\n",
    "    # y_train_fold, y_test_fold = df[\"label\"].iloc[train_index], df[\"label\"].iloc[test_index]\n",
    "x_train_fold = pd.read_csv('data/x_train_fold_mirror2.csv')\n",
    "x_test_fold = pd.read_csv('data/x_test_fold_mirror2.csv')\n",
    "class_weights = compute_class_weight(class_weight='balanced',classes=np.unique(x_train_fold['label']),y=np.ravel(x_train_fold[\"label\"]))\n",
    "# print(class_weights)\n",
    "# class_weights_list.append(class_weights)\n",
    "batch_size = 7\n",
    "optimizer.zero_grad()\n",
    "loss_range = []\n",
    "acc_test = []\n",
    "acc_train = []\n",
    "position_embedding = positional_encoding(2 * len_half_protein_used + 2 , 1280).to(device)\n",
    "for epoc in range(40):\n",
    "    label_need_train = []\n",
    "    label_pred_train = []\n",
    "    label_need = []\n",
    "    label_pred = []\n",
    "    i = 0\n",
    "    loss_onebatch = 0\n",
    "    x_train_fold = x_train_fold.sample(frac=1).reset_index(drop=True)\n",
    "    data_reader = PandasDataReader(x_train_fold, batch_size=batch_size, shuffle=True)\n",
    "    num_epochs = len(x_train_fold)\n",
    "    for batch in data_reader:\n",
    "        if False:\n",
    "            loss = model([batch[\"mut0\"]],[ batch[\"mut1\"]], [batch[\"par0\"]], [max(int(batch[\"Feature range(s)\"][0].split(\"-\")[0])-25,0),max(int(batch[\"Feature range(s)\"][0].split(\"-\")[0])-25,0)+50],class_weights,[batch[\"label\"]],device) # 三个序列和需要的突变采样位置，如突变从80号开始就是[80-25，80+25]\n",
    "            loss_onebatch = loss_onebatch + loss.item()\n",
    "        else:\n",
    "            positions = batch[\"position\"].tolist()\n",
    "            # print([sequence for sequence in batch[\"mut0\"]][0])\n",
    "            mut0,mut0_mask = esm_model.encode([sequence for sequence in batch[\"mut0\"]])\n",
    "            mut1,mut1_mask = esm_model.encode([sequence for sequence in batch[\"mut1\"]])\n",
    "            par0,par0_mask = esm_model.encode([sequence for sequence in batch[\"par0\"]])\n",
    "            # #类似位置编码，标记突变前后的\n",
    "            # zero_row = torch.zeros(mut0.shape[0], mut0.shape[1], 1).to(device)\n",
    "            # mut0 = torch.cat((mut0, zero_row), dim=-1)\n",
    "            # zero_row = torch.ones(mut1.shape[0], mut1.shape[1], 1).to(device)\n",
    "            # mut1 = torch.cat((mut1, zero_row), dim=-1)\n",
    "            #处理mut0，mut1，去除0，找到位置，接入全局变量，01拼接在模型里\n",
    "            # mut0 = mut0[:, 1:, :]\n",
    "            if mut0.shape[1] < 2*len_half_protein_used:\n",
    "                mut0 = torch.cat((mut0.mean(dim=1, keepdim=True),mut0),dim=1)\n",
    "                mut0_mask = mut0_mask\n",
    "                mut1 = torch.cat((mut1.mean(dim=1, keepdim=True),mut1),dim=1)\n",
    "                mut1_mask = mut1_mask\n",
    "            else:\n",
    "                result = torch.randn(mut0.shape[0],2*len_half_protein_used,mut0.shape[2])\n",
    "                result_padding = (np.random.randint(0, 2, size=(mut0.shape[0], 2*len_half_protein_used)) == 1)\n",
    "\n",
    "                for ia in range(len(positions)):\n",
    "                    position = int(positions[ia])\n",
    "                    if position - len_half_protein_used < 0 :\n",
    "                        result[ia, :, :] = mut0[ia,:2 * len_half_protein_used,:]\n",
    "                        result_padding[ia, :] = mut0_mask[ia,:2 * len_half_protein_used].cpu()\n",
    "                    elif position + len_half_protein_used > mut0.shape[1] :\n",
    "                        result[ia, :, :] = mut0[ia,-2 * len_half_protein_used:,:]\n",
    "                        result_padding[ia, :] = mut0_mask[ia, -2 * len_half_protein_used].cpu()\n",
    "                    else:\n",
    "                        result[ia, :, :] = mut0[ia,position - len_half_protein_used:position + len_half_protein_used,:]\n",
    "                        result_padding[ia, :] = mut0_mask[ia, position - len_half_protein_used : position + len_half_protein_used].cpu()\n",
    "\n",
    "                mut0 = torch.cat((mut0.mean(dim=1, keepdim=True).cpu(), result),dim=1)\n",
    "                mut0_mask = result_padding\n",
    "                mut0_mask = np.concatenate([np.full((mut0_mask.shape[0], 1), False), mut0_mask], axis=1)\n",
    "                \n",
    "                \n",
    "                \n",
    "                result = torch.randn(mut1.shape[0],2*len_half_protein_used,mut1.shape[2])\n",
    "                result_padding = (np.random.randint(0, 2, size=(mut1.shape[0], 2*len_half_protein_used)) == 1)\n",
    "                for ia in range(len(positions)):\n",
    "                    position = int(positions[ia])\n",
    "                    if position - len_half_protein_used < 0 :\n",
    "                        result[ia, :, :] = mut1[ia,:2 * len_half_protein_used,:]\n",
    "                        result_padding[ia, :] = mut1_mask[ia,:2 * len_half_protein_used].cpu()\n",
    "                    elif position + len_half_protein_used > mut1.shape[1] :\n",
    "                        result[ia, :, :] = mut1[ia,-2 * len_half_protein_used : ,:]\n",
    "                        result_padding[ia, :] = mut1_mask[ia, -2 * len_half_protein_used].cpu()\n",
    "                    else:\n",
    "                        # print(i)\n",
    "                        result[ia, :, :] = mut1[ia,position - len_half_protein_used:position + len_half_protein_used,:]\n",
    "                        result_padding[ia, :] = mut1_mask[ia, position - len_half_protein_used: position + len_half_protein_used].cpu()\n",
    "                mut1 = torch.cat((mut1.mean(dim=1, keepdim=True).cpu(), result),dim=1)\n",
    "                mut1_mask = result_padding\n",
    "                mut1_mask = np.concatenate([np.full((mut1_mask.shape[0], 1), False), mut1_mask], axis=1)\n",
    "                \n",
    "                \n",
    "            mut0_mask = torch.from_numpy(mut0_mask)\n",
    "            mut0_mask = mut0_mask.to(device)\n",
    "            mut1_mask = torch.from_numpy(mut1_mask)\n",
    "            mut1_mask = mut1_mask.to(device)\n",
    "            mut0 = mut0.to(device)\n",
    "            mut1 = mut1.to(device)\n",
    "            mut0 = mut0 + position_embedding[:mut0.shape[1] , : ]\n",
    "            mut1 = mut1 + position_embedding[2 * len_half_protein_used + 1 : 2 * len_half_protein_used + 1 + mut1.shape[1] , : ]\n",
    "            par0 = par0.to(device)\n",
    "            # par0_mask = torch.from_numpy(par0_mask)\n",
    "            # for position in batch[\"Feature range(s)\"]:\n",
    "            #     positions.append([max(int(position[0].split(\"-\")[0])-25,0),max(int(position[0].split(\"-\")[0])-25,0)+50])\n",
    "            out = model(mut0, mut1, par0, mut0_mask, mut1_mask, par0_mask, class_weights, batch[\"label\"])\n",
    "            loss = model_loss(batch[\"label\"], out,class_weights)\n",
    "            _, predicted_labels = torch.max(out, 1)\n",
    "            if torch.isnan(loss):\n",
    "                break\n",
    "            # break\n",
    "            # loss = ghm_loss(out, batch[\"label\"].to_list())\n",
    "            # loss_onebatch = loss_onebatch + loss.item()\n",
    "            loss_range.append(loss.item())\n",
    "            # print(loss.item())\n",
    "            \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        print(\"done\")\n",
    "        label_need_train = label_need_train + batch[\"label\"].to_list()\n",
    "        label_pred_train = label_pred_train + predicted_labels.tolist()\n",
    "        if (i) % batch_size*20 == 0:\n",
    "            clear_output()\n",
    "            print(f' [{i}/{num_epochs}], Loss: {loss}')\n",
    "\n",
    "        i = i+batch_size\n",
    "    accuracy = accuracy_score(label_need_train,label_pred_train)\n",
    "    acc_train.append(accuracy)\n",
    "    torch.save(model.state_dict(), 'model_params_mirror22.pth')\n",
    "    model.eval()\n",
    "    data_reader = PandasDataReader(x_test_fold, batch_size=10, shuffle=True)\n",
    "    num_epochs = len(x_train_fold)\n",
    "    print(\"testing\",epoc)\n",
    "    for batch in data_reader:\n",
    "        if False:\n",
    "            loss = model([batch[\"mut0\"]],[ batch[\"mut1\"]], [batch[\"par0\"]], [max(int(batch[\"Feature range(s)\"][0].split(\"-\")[0])-25,0),max(int(batch[\"Feature range(s)\"][0].split(\"-\")[0])-25,0)+50],class_weights,[batch[\"label\"]],device) # 三个序列和需要的突变采样位置，如突变从80号开始就是[80-25，80+25]\n",
    "            loss_onebatch = loss_onebatch + loss.item()\n",
    "        else:\n",
    "            positions = batch[\"position\"].tolist()\n",
    "            # print([sequence for sequence in batch[\"mut0\"]][0])\n",
    "            mut0,mut0_mask = esm_model.encode([sequence for sequence in batch[\"mut0\"]])\n",
    "            mut1,mut1_mask = esm_model.encode([sequence for sequence in batch[\"mut1\"]])\n",
    "            par0,par0_mask = esm_model.encode([sequence for sequence in batch[\"par0\"]])\n",
    "            # zero_row = torch.zeros(mut0.shape[0], mut0.shape[1], 1).to(device)\n",
    "            # mut0 = torch.cat((mut0, zero_row), dim=-1)\n",
    "            # zero_row = torch.ones(mut1.shape[0], mut1.shape[1], 1).to(device)\n",
    "            # mut1 = torch.cat((mut1, zero_row), dim=-1)\n",
    "            #处理mut0，mut1，去除0，找到位置，接入全局变量，01拼接在模型里\n",
    "            # mut0 = mut0[:, 1:, :]\n",
    "            if mut0.shape[1] < 2*len_half_protein_used:\n",
    "                mut0 = torch.cat((mut0.mean(dim=1, keepdim=True),mut0),dim=1)\n",
    "                mut0_mask = mut0_mask\n",
    "                mut1 = torch.cat((mut1.mean(dim=1, keepdim=True),mut1),dim=1)\n",
    "                mut1_mask = mut1_mask\n",
    "            else:\n",
    "                result = torch.randn(mut0.shape[0],2*len_half_protein_used,mut0.shape[2])\n",
    "                result_padding = (np.random.randint(0, 2, size=(mut0.shape[0], 2*len_half_protein_used)) == 1)\n",
    "\n",
    "                for ia in range(len(positions)):\n",
    "                    position = int(positions[ia])\n",
    "                    if position - len_half_protein_used < 0 :\n",
    "                        result[ia, :, :] = mut0[ia,:2 * len_half_protein_used,:]\n",
    "                        result_padding[ia, :] = mut0_mask[ia, : 2 * len_half_protein_used].cpu()\n",
    "                    elif position + len_half_protein_used > mut0.shape[1] :\n",
    "                        result[ia, :, :] = mut0[ia,-2 * len_half_protein_used:,:]\n",
    "                        result_padding[ia, :] = mut0_mask[ia, -2 * len_half_protein_used].cpu()\n",
    "                    else:\n",
    "                        result[ia, :, :] = mut0[ia,position - len_half_protein_used:position + len_half_protein_used,:]\n",
    "                        result_padding[ia, :] = mut0_mask[ia, position - len_half_protein_used : position + len_half_protein_used].cpu()\n",
    "\n",
    "                mut0 = torch.cat((mut0.mean(dim=1, keepdim=True).cpu(), result),dim=1)\n",
    "                mut0_mask = result_padding\n",
    "                mut0_mask = np.concatenate([np.full((mut0_mask.shape[0], 1), False), mut0_mask], axis=1)\n",
    "                \n",
    "                \n",
    "                \n",
    "                result = torch.randn(mut1.shape[0],2*len_half_protein_used,mut1.shape[2])\n",
    "                result_padding = (np.random.randint(0, 2, size=(mut1.shape[0], 2*len_half_protein_used)) == 1)\n",
    "                for ia in range(len(positions)):\n",
    "                    position = int(positions[ia])\n",
    "                    if position - len_half_protein_used < 0 :\n",
    "                        result[ia, :, :] = mut1[ia,:2 * len_half_protein_used,:]\n",
    "                        result_padding[ia, :] = mut1_mask[ia , : 2 * len_half_protein_used].cpu()\n",
    "                    elif position + len_half_protein_used > mut1.shape[1] :\n",
    "                        result[ia, :, :] = mut1[ia,-2 * len_half_protein_used : ,:]\n",
    "                        result_padding[ia, :] = mut1_mask[ia , -2 * len_half_protein_used].cpu()\n",
    "                    else:\n",
    "                        # print(i)\n",
    "                        result[ia, :, :] = mut1[ia,position - len_half_protein_used:position + len_half_protein_used,:]\n",
    "                        result_padding[ia, :] = mut1_mask[ia, position - len_half_protein_used : position + len_half_protein_used].cpu()\n",
    "                mut1 = torch.cat((mut1.mean(dim=1, keepdim=True).cpu(), result),dim=1)\n",
    "                mut1_mask = result_padding\n",
    "                mut1_mask = np.concatenate([np.full((mut1_mask.shape[0], 1), False), mut1_mask], axis=1)\n",
    "                \n",
    "                \n",
    "            mut0_mask = torch.from_numpy(mut0_mask)\n",
    "            mut0_mask = mut0_mask.to(device)\n",
    "            mut1_mask = torch.from_numpy(mut1_mask)\n",
    "            mut1_mask = mut1_mask.to(device)\n",
    "            mut0 = mut0.to(device)\n",
    "            mut1 = mut1.to(device)\n",
    "            par0 = par0.to(device)\n",
    "            mut0 = mut0 + position_embedding[:mut0.shape[1] , : ]\n",
    "            mut1 = mut1 + position_embedding[2 * len_half_protein_used + 1 : 2 * len_half_protein_used + 1 + mut1.shape[1] , : ]\n",
    "            x = model(mut0, mut1, par0, mut0_mask,mut1_mask, par0_mask, class_weights,batch[\"label\"])\n",
    "            _, predicted = torch.max(x, 1)\n",
    "            label_pred = label_pred + predicted.tolist()\n",
    "            label_need = label_need + batch['label'].to_list()\n",
    "    accuracy = accuracy_score(label_need, label_pred)\n",
    "    acc_test.append(accuracy)\n",
    "    model.train()\n",
    "    with open('test_result_mirror22.json', 'w') as file:\n",
    "        json.dump(acc_test, file)\n",
    "    with open('train_result_mirror22.json', 'w') as file:\n",
    "        json.dump(acc_train, file)\n",
    "    with open('label_need_withoutcross2.json', 'w') as file:\n",
    "        json.dump(label_need, file)\n",
    "    with open('label_pred_withoutcross2.json', 'w') as file:\n",
    "        json.dump(label_pred, file)\n",
    "    if torch.isnan(loss):\n",
    "        break\n",
    "    if accuracy > 0.85:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f49130255e036e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-10T13:45:12.257644Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:2\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# from sklearn.utils.class_weight import compute_class_weight\n",
    "# import numpy as np\n",
    "# from IPython.display import clear_output\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# import json\n",
    "# batch_size = 4\n",
    "# # 五折交叉验证\n",
    "# splits = 10\n",
    "# # Create StratifiedKFold object.\n",
    "# # 创建StratifiedKFold对象    StratifiedKFold是sklearn库中的一个类，用于将数据集进行分层抽样设置了4个分割（n_splits=splits），打乱数据顺序（shuffle=True）并设置随机种子（random_state=1）。\n",
    "# skf = StratifiedKFold(n_splits=splits, shuffle=True)# , random_state=1\n",
    "# # device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device('cuda:2')\n",
    "# # 定义优化器\n",
    "# model = Sum_model(device)\n",
    "# print(f\"Using device: {device}\")\n",
    "# model.to(device)\n",
    "# model_loss = GHMC_Loss(device)\n",
    "# esm_model = ESMFeatureEncoder()\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=4e-5, betas=(0.9, 0.999), weight_decay=1e-4, amsgrad=False)\n",
    "# # optimizer = torch.optim.Adam(model.parameters(), lr=6e-5)\n",
    "# for train_index, test_index in skf.split(df,df[\"label\"]):#它接受两个参数：x 和 y，分别表示特征数据和目标数据\n",
    "#     x_train_fold, x_test_fold = df.iloc[train_index], df.iloc[test_index]#iloc是pandas库中的一个属性，用于基于整数位置的索引\n",
    "#     # y_train_fold, y_test_fold = df[\"label\"].iloc[train_index], df[\"label\"].iloc[test_index]\n",
    "# x_train_fold.to_csv('data/x_train_fold_mirror2.csv')\n",
    "# x_test_fold.to_csv('data/x_test_fold_mirror2.csv')\n",
    "# class_weights = compute_class_weight(class_weight='balanced',classes=np.unique(x_train_fold['label']),y=np.ravel(x_train_fold[\"label\"]))\n",
    "# # print(class_weights)\n",
    "# # class_weights_list.append(class_weights)\n",
    "# batch_size = 7\n",
    "# optimizer.zero_grad()\n",
    "# loss_range = []\n",
    "# acc_test = []\n",
    "# acc_train = []\n",
    "# position_embedding = positional_encoding(2 * len_half_protein_used + 2 , 1280).to(device)\n",
    "# for epoc in range(40):\n",
    "#     label_need_train = []\n",
    "#     label_pred_train = []\n",
    "#     label_need = []\n",
    "#     label_pred = []\n",
    "#     i = 0\n",
    "#     loss_onebatch = 0\n",
    "#     x_train_fold = x_train_fold.sample(frac=1).reset_index(drop=True)\n",
    "#     data_reader = PandasDataReader(x_train_fold, batch_size=batch_size, shuffle=True)\n",
    "#     num_epochs = len(x_train_fold)\n",
    "#     for batch in data_reader:\n",
    "#         if False:\n",
    "#             loss = model([batch[\"mut0\"]],[ batch[\"mut1\"]], [batch[\"par0\"]], [max(int(batch[\"Feature range(s)\"][0].split(\"-\")[0])-25,0),max(int(batch[\"Feature range(s)\"][0].split(\"-\")[0])-25,0)+50],class_weights,[batch[\"label\"]],device) # 三个序列和需要的突变采样位置，如突变从80号开始就是[80-25，80+25]\n",
    "#             loss_onebatch = loss_onebatch + loss.item()\n",
    "#         else:\n",
    "#             positions = batch[\"position\"].tolist()\n",
    "#             # print([sequence for sequence in batch[\"mut0\"]][0])\n",
    "#             mut0,mut0_mask = esm_model.encode([sequence for sequence in batch[\"mut0\"]])\n",
    "#             mut1,mut1_mask = esm_model.encode([sequence for sequence in batch[\"mut1\"]])\n",
    "#             par0,par0_mask = esm_model.encode([sequence for sequence in batch[\"par0\"]])\n",
    "#             # #类似位置编码，标记突变前后的\n",
    "#             # zero_row = torch.zeros(mut0.shape[0], mut0.shape[1], 1).to(device)\n",
    "#             # mut0 = torch.cat((mut0, zero_row), dim=-1)\n",
    "#             # zero_row = torch.ones(mut1.shape[0], mut1.shape[1], 1).to(device)\n",
    "#             # mut1 = torch.cat((mut1, zero_row), dim=-1)\n",
    "#             #处理mut0，mut1，去除0，找到位置，接入全局变量，01拼接在模型里\n",
    "#             # mut0 = mut0[:, 1:, :]\n",
    "#             if mut0.shape[1] < 2*len_half_protein_used:\n",
    "#                 mut0 = torch.cat((mut0.mean(dim=1, keepdim=True),mut0),dim=1)\n",
    "#                 mut0_mask = mut0_mask\n",
    "#                 mut1 = torch.cat((mut1.mean(dim=1, keepdim=True),mut1),dim=1)\n",
    "#                 mut1_mask = mut1_mask\n",
    "#             else:\n",
    "#                 result = torch.randn(mut0.shape[0],2*len_half_protein_used,mut0.shape[2])\n",
    "#                 result_padding = (np.random.randint(0, 2, size=(mut0.shape[0], 2*len_half_protein_used)) == 1)\n",
    "\n",
    "#                 for ia in range(len(positions)):\n",
    "#                     position = int(positions[ia])\n",
    "#                     if position - len_half_protein_used < 0 :\n",
    "#                         result[ia, :, :] = mut0[ia,:2 * len_half_protein_used,:]\n",
    "#                         result_padding[ia, :] = mut0_mask[ia,:2 * len_half_protein_used].cpu()\n",
    "#                     elif position + len_half_protein_used > mut0.shape[1] :\n",
    "#                         result[ia, :, :] = mut0[ia,-2 * len_half_protein_used:,:]\n",
    "#                         result_padding[ia, :] = mut0_mask[ia, -2 * len_half_protein_used].cpu()\n",
    "#                     else:\n",
    "#                         result[ia, :, :] = mut0[ia,position - len_half_protein_used:position + len_half_protein_used,:]\n",
    "#                         result_padding[ia, :] = mut0_mask[ia, position - len_half_protein_used : position + len_half_protein_used].cpu()\n",
    "\n",
    "#                 mut0 = torch.cat((mut0.mean(dim=1, keepdim=True).cpu(), result),dim=1)\n",
    "#                 mut0_mask = result_padding\n",
    "#                 mut0_mask = np.concatenate([np.full((mut0_mask.shape[0], 1), False), mut0_mask], axis=1)\n",
    "                \n",
    "                \n",
    "                \n",
    "#                 result = torch.randn(mut1.shape[0],2*len_half_protein_used,mut1.shape[2])\n",
    "#                 result_padding = (np.random.randint(0, 2, size=(mut1.shape[0], 2*len_half_protein_used)) == 1)\n",
    "#                 for ia in range(len(positions)):\n",
    "#                     position = int(positions[ia])\n",
    "#                     if position - len_half_protein_used < 0 :\n",
    "#                         result[ia, :, :] = mut1[ia,:2 * len_half_protein_used,:]\n",
    "#                         result_padding[ia, :] = mut1_mask[ia,:2 * len_half_protein_used].cpu()\n",
    "#                     elif position + len_half_protein_used > mut1.shape[1] :\n",
    "#                         result[ia, :, :] = mut1[ia,-2 * len_half_protein_used : ,:]\n",
    "#                         result_padding[ia, :] = mut1_mask[ia, -2 * len_half_protein_used].cpu()\n",
    "#                     else:\n",
    "#                         # print(i)\n",
    "#                         result[ia, :, :] = mut1[ia,position - len_half_protein_used:position + len_half_protein_used,:]\n",
    "#                         result_padding[ia, :] = mut1_mask[ia, position - len_half_protein_used: position + len_half_protein_used].cpu()\n",
    "#                 mut1 = torch.cat((mut1.mean(dim=1, keepdim=True).cpu(), result),dim=1)\n",
    "#                 mut1_mask = result_padding\n",
    "#                 mut1_mask = np.concatenate([np.full((mut1_mask.shape[0], 1), False), mut1_mask], axis=1)\n",
    "                \n",
    "                \n",
    "#             mut0_mask = torch.from_numpy(mut0_mask)\n",
    "#             mut0_mask = mut0_mask.to(device)\n",
    "#             mut1_mask = torch.from_numpy(mut1_mask)\n",
    "#             mut1_mask = mut1_mask.to(device)\n",
    "#             mut0 = mut0.to(device)\n",
    "#             mut1 = mut1.to(device)\n",
    "#             mut0 = mut0 + position_embedding[:mut0.shape[1] , : ]\n",
    "#             mut1 = mut1 + position_embedding[2 * len_half_protein_used + 1 : 2 * len_half_protein_used + 1 + mut1.shape[1] , : ]\n",
    "#             par0 = par0.to(device)\n",
    "#             # par0_mask = torch.from_numpy(par0_mask)\n",
    "#             # for position in batch[\"Feature range(s)\"]:\n",
    "#             #     positions.append([max(int(position[0].split(\"-\")[0])-25,0),max(int(position[0].split(\"-\")[0])-25,0)+50])\n",
    "#             out = model(mut0, mut1, par0, mut0_mask, mut1_mask, par0_mask, class_weights, batch[\"label\"])\n",
    "#             loss = model_loss(batch[\"label\"], out,class_weights)\n",
    "#             _, predicted_labels = torch.max(out, 1)\n",
    "#             if torch.isnan(loss):\n",
    "#                 break\n",
    "#             # break\n",
    "#             # loss = ghm_loss(out, batch[\"label\"].to_list())\n",
    "#             # loss_onebatch = loss_onebatch + loss.item()\n",
    "#             loss_range.append(loss.item())\n",
    "#             # print(loss.item())\n",
    "            \n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         optimizer.zero_grad()\n",
    "#         print(\"done\")\n",
    "#         label_need_train = label_need_train + batch[\"label\"].to_list()\n",
    "#         label_pred_train = label_pred_train + predicted_labels.tolist()\n",
    "#         if (i) % batch_size*20 == 0:\n",
    "#             clear_output()\n",
    "#             print(f' [{i}/{num_epochs}], Loss: {loss}')\n",
    "\n",
    "#         i = i+batch_size\n",
    "#     accuracy = accuracy_score(label_need_train,label_pred_train)\n",
    "#     acc_train.append(accuracy)\n",
    "#     torch.save(model.state_dict(), 'model_params_mirror2.pth')\n",
    "#     model.eval()\n",
    "#     data_reader = PandasDataReader(x_test_fold, batch_size=10, shuffle=True)\n",
    "#     num_epochs = len(x_train_fold)\n",
    "#     print(\"testing\",epoc)\n",
    "#     for batch in data_reader:\n",
    "#         if False:\n",
    "#             loss = model([batch[\"mut0\"]],[ batch[\"mut1\"]], [batch[\"par0\"]], [max(int(batch[\"Feature range(s)\"][0].split(\"-\")[0])-25,0),max(int(batch[\"Feature range(s)\"][0].split(\"-\")[0])-25,0)+50],class_weights,[batch[\"label\"]],device) # 三个序列和需要的突变采样位置，如突变从80号开始就是[80-25，80+25]\n",
    "#             loss_onebatch = loss_onebatch + loss.item()\n",
    "#         else:\n",
    "#             positions = batch[\"position\"].tolist()\n",
    "#             # print([sequence for sequence in batch[\"mut0\"]][0])\n",
    "#             mut0,mut0_mask = esm_model.encode([sequence for sequence in batch[\"mut0\"]])\n",
    "#             mut1,mut1_mask = esm_model.encode([sequence for sequence in batch[\"mut1\"]])\n",
    "#             par0,par0_mask = esm_model.encode([sequence for sequence in batch[\"par0\"]])\n",
    "#             # zero_row = torch.zeros(mut0.shape[0], mut0.shape[1], 1).to(device)\n",
    "#             # mut0 = torch.cat((mut0, zero_row), dim=-1)\n",
    "#             # zero_row = torch.ones(mut1.shape[0], mut1.shape[1], 1).to(device)\n",
    "#             # mut1 = torch.cat((mut1, zero_row), dim=-1)\n",
    "#             #处理mut0，mut1，去除0，找到位置，接入全局变量，01拼接在模型里\n",
    "#             # mut0 = mut0[:, 1:, :]\n",
    "#             if mut0.shape[1] < 2*len_half_protein_used:\n",
    "#                 mut0 = torch.cat((mut0.mean(dim=1, keepdim=True),mut0),dim=1)\n",
    "#                 mut0_mask = mut0_mask\n",
    "#                 mut1 = torch.cat((mut1.mean(dim=1, keepdim=True),mut1),dim=1)\n",
    "#                 mut1_mask = mut1_mask\n",
    "#             else:\n",
    "#                 result = torch.randn(mut0.shape[0],2*len_half_protein_used,mut0.shape[2])\n",
    "#                 result_padding = (np.random.randint(0, 2, size=(mut0.shape[0], 2*len_half_protein_used)) == 1)\n",
    "\n",
    "#                 for ia in range(len(positions)):\n",
    "#                     position = int(positions[ia])\n",
    "#                     if position - len_half_protein_used < 0 :\n",
    "#                         result[ia, :, :] = mut0[ia,:2 * len_half_protein_used,:]\n",
    "#                         result_padding[ia, :] = mut0_mask[ia, : 2 * len_half_protein_used].cpu()\n",
    "#                     elif position + len_half_protein_used > mut0.shape[1] :\n",
    "#                         result[ia, :, :] = mut0[ia,-2 * len_half_protein_used:,:]\n",
    "#                         result_padding[ia, :] = mut0_mask[ia, -2 * len_half_protein_used].cpu()\n",
    "#                     else:\n",
    "#                         result[ia, :, :] = mut0[ia,position - len_half_protein_used:position + len_half_protein_used,:]\n",
    "#                         result_padding[ia, :] = mut0_mask[ia, position - len_half_protein_used : position + len_half_protein_used].cpu()\n",
    "\n",
    "#                 mut0 = torch.cat((mut0.mean(dim=1, keepdim=True).cpu(), result),dim=1)\n",
    "#                 mut0_mask = result_padding\n",
    "#                 mut0_mask = np.concatenate([np.full((mut0_mask.shape[0], 1), False), mut0_mask], axis=1)\n",
    "                \n",
    "                \n",
    "                \n",
    "#                 result = torch.randn(mut1.shape[0],2*len_half_protein_used,mut1.shape[2])\n",
    "#                 result_padding = (np.random.randint(0, 2, size=(mut1.shape[0], 2*len_half_protein_used)) == 1)\n",
    "#                 for ia in range(len(positions)):\n",
    "#                     position = int(positions[ia])\n",
    "#                     if position - len_half_protein_used < 0 :\n",
    "#                         result[ia, :, :] = mut1[ia,:2 * len_half_protein_used,:]\n",
    "#                         result_padding[ia, :] = mut1_mask[ia , : 2 * len_half_protein_used].cpu()\n",
    "#                     elif position + len_half_protein_used > mut1.shape[1] :\n",
    "#                         result[ia, :, :] = mut1[ia,-2 * len_half_protein_used : ,:]\n",
    "#                         result_padding[ia, :] = mut1_mask[ia , -2 * len_half_protein_used].cpu()\n",
    "#                     else:\n",
    "#                         # print(i)\n",
    "#                         result[ia, :, :] = mut1[ia,position - len_half_protein_used:position + len_half_protein_used,:]\n",
    "#                         result_padding[ia, :] = mut1_mask[ia, position - len_half_protein_used : position + len_half_protein_used].cpu()\n",
    "#                 mut1 = torch.cat((mut1.mean(dim=1, keepdim=True).cpu(), result),dim=1)\n",
    "#                 mut1_mask = result_padding\n",
    "#                 mut1_mask = np.concatenate([np.full((mut1_mask.shape[0], 1), False), mut1_mask], axis=1)\n",
    "                \n",
    "                \n",
    "#             mut0_mask = torch.from_numpy(mut0_mask)\n",
    "#             mut0_mask = mut0_mask.to(device)\n",
    "#             mut1_mask = torch.from_numpy(mut1_mask)\n",
    "#             mut1_mask = mut1_mask.to(device)\n",
    "#             mut0 = mut0.to(device)\n",
    "#             mut1 = mut1.to(device)\n",
    "#             par0 = par0.to(device)\n",
    "#             mut0 = mut0 + position_embedding[:mut0.shape[1] , : ]\n",
    "#             mut1 = mut1 + position_embedding[2 * len_half_protein_used + 1 : 2 * len_half_protein_used + 1 + mut1.shape[1] , : ]\n",
    "#             x = model(mut0, mut1, par0, mut0_mask,mut1_mask, par0_mask, class_weights,batch[\"label\"])\n",
    "#             _, predicted = torch.max(x, 1)\n",
    "#             label_pred = label_pred + predicted.tolist()\n",
    "#             label_need = label_need + batch['label'].to_list()\n",
    "#     accuracy = accuracy_score(label_need, label_pred)\n",
    "#     acc_test.append(accuracy)\n",
    "#     model.train()\n",
    "#     with open('test_result_mirror2.json', 'w') as file:\n",
    "#         json.dump(acc_test, file)\n",
    "#     with open('train_result_mirror2.json', 'w') as file:\n",
    "#         json.dump(acc_train, file)\n",
    "#     if torch.isnan(loss):\n",
    "#         break\n",
    "#     if accuracy > 0.85:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab6b3f6-0077-4947-9f2b-4f52e13fc32c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#Feature AC</th>\n",
       "      <th>Feature range(s)</th>\n",
       "      <th>Original sequence</th>\n",
       "      <th>Resulting sequence</th>\n",
       "      <th>Feature short label</th>\n",
       "      <th>Feature type</th>\n",
       "      <th>Feature annotation</th>\n",
       "      <th>Affected protein AC</th>\n",
       "      <th>Affected protein symbol</th>\n",
       "      <th>Affected protein full name</th>\n",
       "      <th>...</th>\n",
       "      <th>n_partner</th>\n",
       "      <th>mutAC</th>\n",
       "      <th>mut0</th>\n",
       "      <th>parAC</th>\n",
       "      <th>par0</th>\n",
       "      <th>mut1</th>\n",
       "      <th>label</th>\n",
       "      <th>mutAC1</th>\n",
       "      <th>position_total</th>\n",
       "      <th>position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>EBI-1004557</td>\n",
       "      <td>[275-275]</td>\n",
       "      <td>[A]</td>\n",
       "      <td>[E]</td>\n",
       "      <td>p.Ala275Glu</td>\n",
       "      <td>mutation decreasing(MI:0119)</td>\n",
       "      <td></td>\n",
       "      <td>Q9GSX9-1</td>\n",
       "      <td>ric-8</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>Q9GSX9</td>\n",
       "      <td>MSEELHSDLIASIFGGKPAKIEEFFSKWNFANAAVSKFDMANSAKN...</td>\n",
       "      <td>P51875</td>\n",
       "      <td>MGCTMSQEERAALERSRMIEKNLKEDGMQAAKDIKLLLLGAGESGK...</td>\n",
       "      <td>MSEELHSDLIASIFGGKPAKIEEFFSKWNFANAAVSKFDMANSAKN...</td>\n",
       "      <td>1</td>\n",
       "      <td>Q9GSX9_Ala275Glu</td>\n",
       "      <td>[275]</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>EBI-10049386</td>\n",
       "      <td>[90-90]</td>\n",
       "      <td>[T]</td>\n",
       "      <td>[A]</td>\n",
       "      <td>p.Thr90Ala</td>\n",
       "      <td>mutation decreasing rate(MI:1130)</td>\n",
       "      <td></td>\n",
       "      <td>Q06830</td>\n",
       "      <td>PRDX1</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>Q06830</td>\n",
       "      <td>MSSGNAKIGHPAPNFKATAVMPDGQFKDISLSDYKGKYVVFFFYPL...</td>\n",
       "      <td>Q13043</td>\n",
       "      <td>METVQLRNPPRRQLKKLDEDSLTKQPEEVFDVLEKLGEGSYGSVYK...</td>\n",
       "      <td>MSSGNAKIGHPAPNFKATAVMPDGQFKDISLSDYKGKYVVFFFYPL...</td>\n",
       "      <td>1</td>\n",
       "      <td>Q06830_Thr90Ala</td>\n",
       "      <td>[90]</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>EBI-10049390</td>\n",
       "      <td>[156-156]</td>\n",
       "      <td>[T]</td>\n",
       "      <td>[A]</td>\n",
       "      <td>p.Thr156Ala</td>\n",
       "      <td>mutation decreasing rate(MI:1130)</td>\n",
       "      <td></td>\n",
       "      <td>Q06830</td>\n",
       "      <td>PRDX1</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>Q06830</td>\n",
       "      <td>MSSGNAKIGHPAPNFKATAVMPDGQFKDISLSDYKGKYVVFFFYPL...</td>\n",
       "      <td>Q13043</td>\n",
       "      <td>METVQLRNPPRRQLKKLDEDSLTKQPEEVFDVLEKLGEGSYGSVYK...</td>\n",
       "      <td>MSSGNAKIGHPAPNFKATAVMPDGQFKDISLSDYKGKYVVFFFYPL...</td>\n",
       "      <td>1</td>\n",
       "      <td>Q06830_Thr156Ala</td>\n",
       "      <td>[156]</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>EBI-10051267</td>\n",
       "      <td>[283-283]</td>\n",
       "      <td>[Q]</td>\n",
       "      <td>[P]</td>\n",
       "      <td>p.Gln283Pro</td>\n",
       "      <td>mutation disrupting(MI:0573)</td>\n",
       "      <td>MI:0612 (comment): Variant detected in HFE1 [M...</td>\n",
       "      <td>Q30201</td>\n",
       "      <td>HFE</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>Q30201</td>\n",
       "      <td>MGPRARPALLLLMLLQTAVLQGRLLRSHSLHYLFMGASEQDLGLSL...</td>\n",
       "      <td>P61769</td>\n",
       "      <td>MSRSVALAVLALLSLSGLEAIQRTPKIQVYSRHPAENGKSNFLNCY...</td>\n",
       "      <td>MGPRARPALLLLMLLQTAVLQGRLLRSHSLHYLFMGASEQDLGLSL...</td>\n",
       "      <td>0</td>\n",
       "      <td>Q30201_Gln283Pro</td>\n",
       "      <td>[283]</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>EBI-10051292</td>\n",
       "      <td>[283-283]</td>\n",
       "      <td>[Q]</td>\n",
       "      <td>[P]</td>\n",
       "      <td>p.Gln283Pro</td>\n",
       "      <td>mutation disrupting(MI:0573)</td>\n",
       "      <td>MI:0612 (comment): Variant detected in HFE1 [M...</td>\n",
       "      <td>Q30201</td>\n",
       "      <td>HFE</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>Q30201</td>\n",
       "      <td>MGPRARPALLLLMLLQTAVLQGRLLRSHSLHYLFMGASEQDLGLSL...</td>\n",
       "      <td>P02786</td>\n",
       "      <td>MMDQARSAFSNLFGGEPLSYTRFSLARQVDGDNSHVEMKLAVDEEE...</td>\n",
       "      <td>MGPRARPALLLLMLLQTAVLQGRLLRSHSLHYLFMGASEQDLGLSL...</td>\n",
       "      <td>0</td>\n",
       "      <td>Q30201_Gln283Pro</td>\n",
       "      <td>[283]</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     #Feature AC Feature range(s) Original sequence Resulting sequence  \\\n",
       "16   EBI-1004557        [275-275]               [A]                [E]   \n",
       "25  EBI-10049386          [90-90]               [T]                [A]   \n",
       "27  EBI-10049390        [156-156]               [T]                [A]   \n",
       "36  EBI-10051267        [283-283]               [Q]                [P]   \n",
       "38  EBI-10051292        [283-283]               [Q]                [P]   \n",
       "\n",
       "   Feature short label                       Feature type  \\\n",
       "16         p.Ala275Glu       mutation decreasing(MI:0119)   \n",
       "25          p.Thr90Ala  mutation decreasing rate(MI:1130)   \n",
       "27         p.Thr156Ala  mutation decreasing rate(MI:1130)   \n",
       "36         p.Gln283Pro       mutation disrupting(MI:0573)   \n",
       "38         p.Gln283Pro       mutation disrupting(MI:0573)   \n",
       "\n",
       "                                   Feature annotation Affected protein AC  \\\n",
       "16                                                               Q9GSX9-1   \n",
       "25                                                                 Q06830   \n",
       "27                                                                 Q06830   \n",
       "36  MI:0612 (comment): Variant detected in HFE1 [M...              Q30201   \n",
       "38  MI:0612 (comment): Variant detected in HFE1 [M...              Q30201   \n",
       "\n",
       "   Affected protein symbol Affected protein full name  ... n_partner   mutAC  \\\n",
       "16                   ric-8                             ...         2  Q9GSX9   \n",
       "25                   PRDX1                             ...         2  Q06830   \n",
       "27                   PRDX1                             ...         2  Q06830   \n",
       "36                     HFE                             ...         2  Q30201   \n",
       "38                     HFE                             ...         2  Q30201   \n",
       "\n",
       "                                                 mut0   parAC  \\\n",
       "16  MSEELHSDLIASIFGGKPAKIEEFFSKWNFANAAVSKFDMANSAKN...  P51875   \n",
       "25  MSSGNAKIGHPAPNFKATAVMPDGQFKDISLSDYKGKYVVFFFYPL...  Q13043   \n",
       "27  MSSGNAKIGHPAPNFKATAVMPDGQFKDISLSDYKGKYVVFFFYPL...  Q13043   \n",
       "36  MGPRARPALLLLMLLQTAVLQGRLLRSHSLHYLFMGASEQDLGLSL...  P61769   \n",
       "38  MGPRARPALLLLMLLQTAVLQGRLLRSHSLHYLFMGASEQDLGLSL...  P02786   \n",
       "\n",
       "                                                 par0  \\\n",
       "16  MGCTMSQEERAALERSRMIEKNLKEDGMQAAKDIKLLLLGAGESGK...   \n",
       "25  METVQLRNPPRRQLKKLDEDSLTKQPEEVFDVLEKLGEGSYGSVYK...   \n",
       "27  METVQLRNPPRRQLKKLDEDSLTKQPEEVFDVLEKLGEGSYGSVYK...   \n",
       "36  MSRSVALAVLALLSLSGLEAIQRTPKIQVYSRHPAENGKSNFLNCY...   \n",
       "38  MMDQARSAFSNLFGGEPLSYTRFSLARQVDGDNSHVEMKLAVDEEE...   \n",
       "\n",
       "                                                 mut1  label  \\\n",
       "16  MSEELHSDLIASIFGGKPAKIEEFFSKWNFANAAVSKFDMANSAKN...      1   \n",
       "25  MSSGNAKIGHPAPNFKATAVMPDGQFKDISLSDYKGKYVVFFFYPL...      1   \n",
       "27  MSSGNAKIGHPAPNFKATAVMPDGQFKDISLSDYKGKYVVFFFYPL...      1   \n",
       "36  MGPRARPALLLLMLLQTAVLQGRLLRSHSLHYLFMGASEQDLGLSL...      0   \n",
       "38  MGPRARPALLLLMLLQTAVLQGRLLRSHSLHYLFMGASEQDLGLSL...      0   \n",
       "\n",
       "              mutAC1 position_total position  \n",
       "16  Q9GSX9_Ala275Glu          [275]      275  \n",
       "25   Q06830_Thr90Ala           [90]       90  \n",
       "27  Q06830_Thr156Ala          [156]      156  \n",
       "36  Q30201_Gln283Pro          [283]      283  \n",
       "38  Q30201_Gln283Pro          [283]      283  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#Feature AC</th>\n",
       "      <th>Feature range(s)</th>\n",
       "      <th>Original sequence</th>\n",
       "      <th>Resulting sequence</th>\n",
       "      <th>Feature short label</th>\n",
       "      <th>Feature type</th>\n",
       "      <th>Feature annotation</th>\n",
       "      <th>Affected protein AC</th>\n",
       "      <th>Affected protein symbol</th>\n",
       "      <th>Affected protein full name</th>\n",
       "      <th>...</th>\n",
       "      <th>n_partner</th>\n",
       "      <th>mutAC</th>\n",
       "      <th>mut0</th>\n",
       "      <th>parAC</th>\n",
       "      <th>par0</th>\n",
       "      <th>mut1</th>\n",
       "      <th>label</th>\n",
       "      <th>mutAC1</th>\n",
       "      <th>position_total</th>\n",
       "      <th>position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>EBI-10041299</td>\n",
       "      <td>[108-108]</td>\n",
       "      <td>[E]</td>\n",
       "      <td>[R]</td>\n",
       "      <td>p.Glu108Arg</td>\n",
       "      <td>mutation decreasing(MI:0119)</td>\n",
       "      <td></td>\n",
       "      <td>P60604</td>\n",
       "      <td>UBE2G2</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>P60604</td>\n",
       "      <td>MAGTALKRLMAEYKQLTLNPPEGIVAGPMNEENFFEWEALIMGPED...</td>\n",
       "      <td>Q9UKV5</td>\n",
       "      <td>MPLLFLERFPWPSLRTYTGLSGLALLGTIISAYRALSQPEAGPGEP...</td>\n",
       "      <td>MAGTALKRLMAEYKQLTLNPPEGIVAGPMNEENFFEWEALIMGPED...</td>\n",
       "      <td>1</td>\n",
       "      <td>P60604_Glu108Arg</td>\n",
       "      <td>[108]</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>EBI-10049392</td>\n",
       "      <td>[183-183]</td>\n",
       "      <td>[T]</td>\n",
       "      <td>[A]</td>\n",
       "      <td>p.Thr183Ala</td>\n",
       "      <td>mutation decreasing rate(MI:1130)</td>\n",
       "      <td></td>\n",
       "      <td>Q06830</td>\n",
       "      <td>PRDX1</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>Q06830</td>\n",
       "      <td>MSSGNAKIGHPAPNFKATAVMPDGQFKDISLSDYKGKYVVFFFYPL...</td>\n",
       "      <td>Q13043</td>\n",
       "      <td>METVQLRNPPRRQLKKLDEDSLTKQPEEVFDVLEKLGEGSYGSVYK...</td>\n",
       "      <td>MSSGNAKIGHPAPNFKATAVMPDGQFKDISLSDYKGKYVVFFFYPL...</td>\n",
       "      <td>1</td>\n",
       "      <td>Q06830_Thr183Ala</td>\n",
       "      <td>[183]</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>EBI-10051282</td>\n",
       "      <td>[283-283]</td>\n",
       "      <td>[Q]</td>\n",
       "      <td>[P]</td>\n",
       "      <td>p.Gln283Pro</td>\n",
       "      <td>mutation disrupting(MI:0573)</td>\n",
       "      <td>MI:0612 (comment): Variant detected in HFE1 [M...</td>\n",
       "      <td>Q30201</td>\n",
       "      <td>HFE</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>Q30201</td>\n",
       "      <td>MGPRARPALLLLMLLQTAVLQGRLLRSHSLHYLFMGASEQDLGLSL...</td>\n",
       "      <td>P61769</td>\n",
       "      <td>MSRSVALAVLALLSLSGLEAIQRTPKIQVYSRHPAENGKSNFLNCY...</td>\n",
       "      <td>MGPRARPALLLLMLLQTAVLQGRLLRSHSLHYLFMGASEQDLGLSL...</td>\n",
       "      <td>0</td>\n",
       "      <td>Q30201_Gln283Pro</td>\n",
       "      <td>[283]</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>EBI-10051312</td>\n",
       "      <td>[283-283]</td>\n",
       "      <td>[Q]</td>\n",
       "      <td>[P]</td>\n",
       "      <td>p.Gln283Pro</td>\n",
       "      <td>mutation disrupting(MI:0573)</td>\n",
       "      <td>MI:0612 (comment): Variant detected in HFE1 [M...</td>\n",
       "      <td>Q30201</td>\n",
       "      <td>HFE</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>Q30201</td>\n",
       "      <td>MGPRARPALLLLMLLQTAVLQGRLLRSHSLHYLFMGASEQDLGLSL...</td>\n",
       "      <td>P02786</td>\n",
       "      <td>MMDQARSAFSNLFGGEPLSYTRFSLARQVDGDNSHVEMKLAVDEEE...</td>\n",
       "      <td>MGPRARPALLLLMLLQTAVLQGRLLRSHSLHYLFMGASEQDLGLSL...</td>\n",
       "      <td>0</td>\n",
       "      <td>Q30201_Gln283Pro</td>\n",
       "      <td>[283]</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>EBI-1007826</td>\n",
       "      <td>[152-152]</td>\n",
       "      <td>[S]</td>\n",
       "      <td>[W]</td>\n",
       "      <td>p.Ser152Trp</td>\n",
       "      <td>mutation disrupting(MI:0573)</td>\n",
       "      <td></td>\n",
       "      <td>P63005</td>\n",
       "      <td>Pafah1b1</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>P63005</td>\n",
       "      <td>MVLSQRQRDELNRAIADYLRSNGYEEAYSVFKKEAELDMNEELDKK...</td>\n",
       "      <td>Q9ERR1</td>\n",
       "      <td>MDGEDIPDFSSLKEETAYWKELSLKYKQSFQEARDELVEFQEGSRE...</td>\n",
       "      <td>MVLSQRQRDELNRAIADYLRSNGYEEAYSVFKKEAELDMNEELDKK...</td>\n",
       "      <td>0</td>\n",
       "      <td>P63005_Ser152Trp</td>\n",
       "      <td>[152]</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     #Feature AC Feature range(s) Original sequence Resulting sequence  \\\n",
       "11  EBI-10041299        [108-108]               [E]                [R]   \n",
       "28  EBI-10049392        [183-183]               [T]                [A]   \n",
       "37  EBI-10051282        [283-283]               [Q]                [P]   \n",
       "39  EBI-10051312        [283-283]               [Q]                [P]   \n",
       "57   EBI-1007826        [152-152]               [S]                [W]   \n",
       "\n",
       "   Feature short label                       Feature type  \\\n",
       "11         p.Glu108Arg       mutation decreasing(MI:0119)   \n",
       "28         p.Thr183Ala  mutation decreasing rate(MI:1130)   \n",
       "37         p.Gln283Pro       mutation disrupting(MI:0573)   \n",
       "39         p.Gln283Pro       mutation disrupting(MI:0573)   \n",
       "57         p.Ser152Trp       mutation disrupting(MI:0573)   \n",
       "\n",
       "                                   Feature annotation Affected protein AC  \\\n",
       "11                                                                 P60604   \n",
       "28                                                                 Q06830   \n",
       "37  MI:0612 (comment): Variant detected in HFE1 [M...              Q30201   \n",
       "39  MI:0612 (comment): Variant detected in HFE1 [M...              Q30201   \n",
       "57                                                                 P63005   \n",
       "\n",
       "   Affected protein symbol Affected protein full name  ... n_partner   mutAC  \\\n",
       "11                  UBE2G2                             ...         2  P60604   \n",
       "28                   PRDX1                             ...         2  Q06830   \n",
       "37                     HFE                             ...         2  Q30201   \n",
       "39                     HFE                             ...         2  Q30201   \n",
       "57                Pafah1b1                             ...         2  P63005   \n",
       "\n",
       "                                                 mut0   parAC  \\\n",
       "11  MAGTALKRLMAEYKQLTLNPPEGIVAGPMNEENFFEWEALIMGPED...  Q9UKV5   \n",
       "28  MSSGNAKIGHPAPNFKATAVMPDGQFKDISLSDYKGKYVVFFFYPL...  Q13043   \n",
       "37  MGPRARPALLLLMLLQTAVLQGRLLRSHSLHYLFMGASEQDLGLSL...  P61769   \n",
       "39  MGPRARPALLLLMLLQTAVLQGRLLRSHSLHYLFMGASEQDLGLSL...  P02786   \n",
       "57  MVLSQRQRDELNRAIADYLRSNGYEEAYSVFKKEAELDMNEELDKK...  Q9ERR1   \n",
       "\n",
       "                                                 par0  \\\n",
       "11  MPLLFLERFPWPSLRTYTGLSGLALLGTIISAYRALSQPEAGPGEP...   \n",
       "28  METVQLRNPPRRQLKKLDEDSLTKQPEEVFDVLEKLGEGSYGSVYK...   \n",
       "37  MSRSVALAVLALLSLSGLEAIQRTPKIQVYSRHPAENGKSNFLNCY...   \n",
       "39  MMDQARSAFSNLFGGEPLSYTRFSLARQVDGDNSHVEMKLAVDEEE...   \n",
       "57  MDGEDIPDFSSLKEETAYWKELSLKYKQSFQEARDELVEFQEGSRE...   \n",
       "\n",
       "                                                 mut1  label  \\\n",
       "11  MAGTALKRLMAEYKQLTLNPPEGIVAGPMNEENFFEWEALIMGPED...      1   \n",
       "28  MSSGNAKIGHPAPNFKATAVMPDGQFKDISLSDYKGKYVVFFFYPL...      1   \n",
       "37  MGPRARPALLLLMLLQTAVLQGRLLRSHSLHYLFMGASEQDLGLSL...      0   \n",
       "39  MGPRARPALLLLMLLQTAVLQGRLLRSHSLHYLFMGASEQDLGLSL...      0   \n",
       "57  MVLSQRQRDELNRAIADYLRSNGYEEAYSVFKKEAELDMNEELDKK...      0   \n",
       "\n",
       "              mutAC1 position_total position  \n",
       "11  P60604_Glu108Arg          [108]      108  \n",
       "28  Q06830_Thr183Ala          [183]      183  \n",
       "37  Q30201_Gln283Pro          [283]      283  \n",
       "39  Q30201_Gln283Pro          [283]      283  \n",
       "57  P63005_Ser152Trp          [152]      152  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_fold.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeae9423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [4662/26174], Loss: 0.38638001680374146\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4, betas=(0.9, 0.999), weight_decay=1e-6, amsgrad=False)\n",
    "for epoc in range(40):\n",
    "    label_need_train = []\n",
    "    label_pred_train = []\n",
    "    label_need = []\n",
    "    label_pred = []\n",
    "    i = 0\n",
    "    loss_onebatch = 0\n",
    "    x_train_fold = x_train_fold.sample(frac=1).reset_index(drop=True)\n",
    "    data_reader = PandasDataReader(x_train_fold, batch_size=batch_size, shuffle=True)\n",
    "    num_epochs = len(x_train_fold)\n",
    "    for batch in data_reader:\n",
    "        if False:\n",
    "            loss = model([batch[\"mut0\"]],[ batch[\"mut1\"]], [batch[\"par0\"]], [max(int(batch[\"Feature range(s)\"][0].split(\"-\")[0])-25,0),max(int(batch[\"Feature range(s)\"][0].split(\"-\")[0])-25,0)+50],class_weights,[batch[\"label\"]],device) # 三个序列和需要的突变采样位置，如突变从80号开始就是[80-25，80+25]\n",
    "            loss_onebatch = loss_onebatch + loss.item()\n",
    "        else:\n",
    "            positions = batch[\"position\"].tolist()\n",
    "            # print([sequence for sequence in batch[\"mut0\"]][0])\n",
    "            mut0,mut0_mask = esm_model.encode([sequence for sequence in batch[\"mut0\"]])\n",
    "            mut1,mut1_mask = esm_model.encode([sequence for sequence in batch[\"mut1\"]])\n",
    "            par0,par0_mask = esm_model.encode([sequence for sequence in batch[\"par0\"]])\n",
    "            # #类似位置编码，标记突变前后的\n",
    "            # zero_row = torch.zeros(mut0.shape[0], mut0.shape[1], 1).to(device)\n",
    "            # mut0 = torch.cat((mut0, zero_row), dim=-1)\n",
    "            # zero_row = torch.ones(mut1.shape[0], mut1.shape[1], 1).to(device)\n",
    "            # mut1 = torch.cat((mut1, zero_row), dim=-1)\n",
    "            #处理mut0，mut1，去除0，找到位置，接入全局变量，01拼接在模型里\n",
    "            # mut0 = mut0[:, 1:, :]\n",
    "            if mut0.shape[1] < 2*len_half_protein_used:\n",
    "                mut0 = torch.cat((mut0.mean(dim=1, keepdim=True),mut0),dim=1)\n",
    "                mut0_mask = mut0_mask\n",
    "                mut1 = torch.cat((mut1.mean(dim=1, keepdim=True),mut1),dim=1)\n",
    "                mut1_mask = mut1_mask\n",
    "            else:\n",
    "                result = torch.randn(mut0.shape[0],2*len_half_protein_used,mut0.shape[2])\n",
    "                result_padding = (np.random.randint(0, 2, size=(mut0.shape[0], 2*len_half_protein_used)) == 1)\n",
    "\n",
    "                for ia in range(len(positions)):\n",
    "                    position = int(positions[ia])\n",
    "                    if position - len_half_protein_used < 0 :\n",
    "                        result[ia, :, :] = mut0[ia,:2 * len_half_protein_used,:]\n",
    "                        result_padding[ia, :] = mut0_mask[ia,:2 * len_half_protein_used].cpu()\n",
    "                    elif position + len_half_protein_used > mut0.shape[1] :\n",
    "                        result[ia, :, :] = mut0[ia,-2 * len_half_protein_used:,:]\n",
    "                        result_padding[ia, :] = mut0_mask[ia, -2 * len_half_protein_used].cpu()\n",
    "                    else:\n",
    "                        result[ia, :, :] = mut0[ia,position - len_half_protein_used:position + len_half_protein_used,:]\n",
    "                        result_padding[ia, :] = mut0_mask[ia, position - len_half_protein_used : position + len_half_protein_used].cpu()\n",
    "\n",
    "                mut0 = torch.cat((mut0.mean(dim=1, keepdim=True).cpu(), result),dim=1)\n",
    "                mut0_mask = result_padding\n",
    "                mut0_mask = np.concatenate([np.full((mut0_mask.shape[0], 1), False), mut0_mask], axis=1)\n",
    "                \n",
    "                \n",
    "                \n",
    "                result = torch.randn(mut1.shape[0],2*len_half_protein_used,mut1.shape[2])\n",
    "                result_padding = (np.random.randint(0, 2, size=(mut1.shape[0], 2*len_half_protein_used)) == 1)\n",
    "                for ia in range(len(positions)):\n",
    "                    position = int(positions[ia])\n",
    "                    if position - len_half_protein_used < 0 :\n",
    "                        result[ia, :, :] = mut1[ia,:2 * len_half_protein_used,:]\n",
    "                        result_padding[ia, :] = mut1_mask[ia,:2 * len_half_protein_used].cpu()\n",
    "                    elif position + len_half_protein_used > mut1.shape[1] :\n",
    "                        result[ia, :, :] = mut1[ia,-2 * len_half_protein_used : ,:]\n",
    "                        result_padding[ia, :] = mut1_mask[ia, -2 * len_half_protein_used].cpu()\n",
    "                    else:\n",
    "                        # print(i)\n",
    "                        result[ia, :, :] = mut1[ia,position - len_half_protein_used:position + len_half_protein_used,:]\n",
    "                        result_padding[ia, :] = mut1_mask[ia, position - len_half_protein_used: position + len_half_protein_used].cpu()\n",
    "                mut1 = torch.cat((mut1.mean(dim=1, keepdim=True).cpu(), result),dim=1)\n",
    "                mut1_mask = result_padding\n",
    "                mut1_mask = np.concatenate([np.full((mut1_mask.shape[0], 1), False), mut1_mask], axis=1)\n",
    "                \n",
    "                \n",
    "            mut0_mask = torch.from_numpy(mut0_mask)\n",
    "            mut0_mask = mut0_mask.to(device)\n",
    "            mut1_mask = torch.from_numpy(mut1_mask)\n",
    "            mut1_mask = mut1_mask.to(device)\n",
    "            mut0 = mut0.to(device)\n",
    "            mut1 = mut1.to(device)\n",
    "            mut0 = mut0 + position_embedding[:mut0.shape[1] , : ]\n",
    "            mut1 = mut1 + position_embedding[2 * len_half_protein_used + 1 : 2 * len_half_protein_used + 1 + mut1.shape[1] , : ]\n",
    "            par0 = par0.to(device)\n",
    "            # par0_mask = torch.from_numpy(par0_mask)\n",
    "            # for position in batch[\"Feature range(s)\"]:\n",
    "            #     positions.append([max(int(position[0].split(\"-\")[0])-25,0),max(int(position[0].split(\"-\")[0])-25,0)+50])\n",
    "            out = model(mut0, mut1, par0, mut0_mask, mut1_mask, par0_mask, class_weights, batch[\"label\"])\n",
    "            loss = model_loss(batch[\"label\"], out,class_weights)\n",
    "            _, predicted_labels = torch.max(out, 1)\n",
    "            if torch.isnan(loss):\n",
    "                break\n",
    "            # break\n",
    "            # loss = ghm_loss(out, batch[\"label\"].to_list())\n",
    "            # loss_onebatch = loss_onebatch + loss.item()\n",
    "            loss_range.append(loss.item())\n",
    "            # print(loss.item())\n",
    "            \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        print(\"done\")\n",
    "        label_need_train = label_need_train + batch[\"label\"].to_list()\n",
    "        label_pred_train = label_pred_train + predicted_labels.tolist()\n",
    "        if (i) % batch_size*20 == 0:\n",
    "            clear_output()\n",
    "            print(f' [{i}/{num_epochs}], Loss: {loss}')\n",
    "\n",
    "        i = i+batch_size\n",
    "    accuracy = accuracy_score(label_need_train,label_pred_train)\n",
    "    acc_train.append(accuracy)\n",
    "    torch.save(model.state_dict(), 'model_params_mirror2.pth')\n",
    "    model.eval()\n",
    "    data_reader = PandasDataReader(x_test_fold, batch_size=10, shuffle=True)\n",
    "    num_epochs = len(x_train_fold)\n",
    "    print(\"testing\",epoc)\n",
    "    for batch in data_reader:\n",
    "        if False:\n",
    "            loss = model([batch[\"mut0\"]],[ batch[\"mut1\"]], [batch[\"par0\"]], [max(int(batch[\"Feature range(s)\"][0].split(\"-\")[0])-25,0),max(int(batch[\"Feature range(s)\"][0].split(\"-\")[0])-25,0)+50],class_weights,[batch[\"label\"]],device) # 三个序列和需要的突变采样位置，如突变从80号开始就是[80-25，80+25]\n",
    "            loss_onebatch = loss_onebatch + loss.item()\n",
    "        else:\n",
    "            positions = batch[\"position\"].tolist()\n",
    "            # print([sequence for sequence in batch[\"mut0\"]][0])\n",
    "            mut0,mut0_mask = esm_model.encode([sequence for sequence in batch[\"mut0\"]])\n",
    "            mut1,mut1_mask = esm_model.encode([sequence for sequence in batch[\"mut1\"]])\n",
    "            par0,par0_mask = esm_model.encode([sequence for sequence in batch[\"par0\"]])\n",
    "            # zero_row = torch.zeros(mut0.shape[0], mut0.shape[1], 1).to(device)\n",
    "            # mut0 = torch.cat((mut0, zero_row), dim=-1)\n",
    "            # zero_row = torch.ones(mut1.shape[0], mut1.shape[1], 1).to(device)\n",
    "            # mut1 = torch.cat((mut1, zero_row), dim=-1)\n",
    "            #处理mut0，mut1，去除0，找到位置，接入全局变量，01拼接在模型里\n",
    "            # mut0 = mut0[:, 1:, :]\n",
    "            if mut0.shape[1] < 2*len_half_protein_used:\n",
    "                mut0 = torch.cat((mut0.mean(dim=1, keepdim=True),mut0),dim=1)\n",
    "                mut0_mask = mut0_mask\n",
    "                mut1 = torch.cat((mut1.mean(dim=1, keepdim=True),mut1),dim=1)\n",
    "                mut1_mask = mut1_mask\n",
    "            else:\n",
    "                result = torch.randn(mut0.shape[0],2*len_half_protein_used,mut0.shape[2])\n",
    "                result_padding = (np.random.randint(0, 2, size=(mut0.shape[0], 2*len_half_protein_used)) == 1)\n",
    "\n",
    "                for ia in range(len(positions)):\n",
    "                    position = int(positions[ia])\n",
    "                    if position - len_half_protein_used < 0 :\n",
    "                        result[ia, :, :] = mut0[ia,:2 * len_half_protein_used,:]\n",
    "                        result_padding[ia, :] = mut0_mask[ia, : 2 * len_half_protein_used].cpu()\n",
    "                    elif position + len_half_protein_used > mut0.shape[1] :\n",
    "                        result[ia, :, :] = mut0[ia,-2 * len_half_protein_used:,:]\n",
    "                        result_padding[ia, :] = mut0_mask[ia, -2 * len_half_protein_used].cpu()\n",
    "                    else:\n",
    "                        result[ia, :, :] = mut0[ia,position - len_half_protein_used:position + len_half_protein_used,:]\n",
    "                        result_padding[ia, :] = mut0_mask[ia, position - len_half_protein_used : position + len_half_protein_used].cpu()\n",
    "\n",
    "                mut0 = torch.cat((mut0.mean(dim=1, keepdim=True).cpu(), result),dim=1)\n",
    "                mut0_mask = result_padding\n",
    "                mut0_mask = np.concatenate([np.full((mut0_mask.shape[0], 1), False), mut0_mask], axis=1)\n",
    "                \n",
    "                \n",
    "                \n",
    "                result = torch.randn(mut1.shape[0],2*len_half_protein_used,mut1.shape[2])\n",
    "                result_padding = (np.random.randint(0, 2, size=(mut1.shape[0], 2*len_half_protein_used)) == 1)\n",
    "                for ia in range(len(positions)):\n",
    "                    position = int(positions[ia])\n",
    "                    if position - len_half_protein_used < 0 :\n",
    "                        result[ia, :, :] = mut1[ia,:2 * len_half_protein_used,:]\n",
    "                        result_padding[ia, :] = mut1_mask[ia , : 2 * len_half_protein_used].cpu()\n",
    "                    elif position + len_half_protein_used > mut1.shape[1] :\n",
    "                        result[ia, :, :] = mut1[ia,-2 * len_half_protein_used : ,:]\n",
    "                        result_padding[ia, :] = mut1_mask[ia , -2 * len_half_protein_used].cpu()\n",
    "                    else:\n",
    "                        # print(i)\n",
    "                        result[ia, :, :] = mut1[ia,position - len_half_protein_used:position + len_half_protein_used,:]\n",
    "                        result_padding[ia, :] = mut1_mask[ia, position - len_half_protein_used : position + len_half_protein_used].cpu()\n",
    "                mut1 = torch.cat((mut1.mean(dim=1, keepdim=True).cpu(), result),dim=1)\n",
    "                mut1_mask = result_padding\n",
    "                mut1_mask = np.concatenate([np.full((mut1_mask.shape[0], 1), False), mut1_mask], axis=1)\n",
    "                \n",
    "                \n",
    "            mut0_mask = torch.from_numpy(mut0_mask)\n",
    "            mut0_mask = mut0_mask.to(device)\n",
    "            mut1_mask = torch.from_numpy(mut1_mask)\n",
    "            mut1_mask = mut1_mask.to(device)\n",
    "            mut0 = mut0.to(device)\n",
    "            mut1 = mut1.to(device)\n",
    "            par0 = par0.to(device)\n",
    "            mut0 = mut0 + position_embedding[:mut0.shape[1] , : ]\n",
    "            mut1 = mut1 + position_embedding[2 * len_half_protein_used + 1 : 2 * len_half_protein_used + 1 + mut1.shape[1] , : ]\n",
    "            x = model(mut0, mut1, par0, mut0_mask,mut1_mask, par0_mask, class_weights,batch[\"label\"])\n",
    "            _, predicted = torch.max(x, 1)\n",
    "            label_pred = label_pred + predicted.tolist()\n",
    "            label_need = label_need + batch['label'].to_list()\n",
    "    accuracy = accuracy_score(label_need, label_pred)\n",
    "    acc_test.append(accuracy)\n",
    "    model.train()\n",
    "    with open('test_result_mirror2.json', 'w') as file:\n",
    "        json.dump(acc_test, file)\n",
    "    with open('train_result_mirror2.json', 'w') as file:\n",
    "        json.dump(acc_train, file)\n",
    "    if torch.isnan(loss):\n",
    "        break\n",
    "    if accuracy > 0.85:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba35f33c-242d-4829-9168-fc6d7eb117e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 训练集的准确率列表\n",
    "train_accuracy = acc_train\n",
    "\n",
    "# 测试集的准确率列表\n",
    "test_accuracy = acc_test\n",
    "\n",
    "# 对应的epochs或时间步列表\n",
    "epochs = range(len(acc_test))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, train_accuracy, marker='o', label='Train Accuracy')\n",
    "plt.plot(epochs, test_accuracy, marker='s', label='Test Accuracy')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Testing Accuracy over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf38f07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " ...]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_range[-1900:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cedb87-b490-40d5-8fe1-9138b3b88edd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 损失值列表\n",
    "loss_values = loss_range[-1900:]\n",
    "\n",
    "# 对应的epochs或时间步列表\n",
    "epochs = range(len(loss_values))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, loss_values, color='r')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Value over Epochs')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6da0f9-0b3b-484c-8691-3409287fb169",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label_need, label_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58780350-6bc4-460f-b900-0e86a53e24a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label_need_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3306dccf-a3a7-4100-aa5f-e7423051c6ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() missing 1 required positional argument: 'label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 84\u001b[0m\n\u001b[1;32m     80\u001b[0m par0 \u001b[38;5;241m=\u001b[39m par0\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# par0_mask = torch.from_numpy(par0_mask)\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# for position in batch[\"Feature range(s)\"]:\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m#     positions.append([max(int(position[0].split(\"-\")[0])-25,0),max(int(position[0].split(\"-\")[0])-25,0)+50])\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmut0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmut1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpar0\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmut0_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmut1_mask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpar0_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m loss \u001b[38;5;241m=\u001b[39m model_loss(batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m], out,class_weights)\n\u001b[1;32m     86\u001b[0m _, predicted_labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(out, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/lyk_mippi/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/lyk_mippi/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() missing 1 required positional argument: 'label'"
     ]
    }
   ],
   "source": [
    "for epoc in range(40):\n",
    "    label_need_train = []\n",
    "    label_pred_train = []\n",
    "    label_need = []\n",
    "    label_pred = []\n",
    "    i = 0\n",
    "    loss_onebatch = 0\n",
    "    x_train_fold = x_train_fold.sample(frac=1).reset_index(drop=True)\n",
    "    data_reader = PandasDataReader(x_train_fold, batch_size=batch_size, shuffle=True)\n",
    "    num_epochs = len(x_train_fold)\n",
    "    for batch in data_reader:\n",
    "        if False:\n",
    "            loss = model([batch[\"mut0\"]],[ batch[\"mut1\"]], [batch[\"par0\"]], [max(int(batch[\"Feature range(s)\"][0].split(\"-\")[0])-25,0),max(int(batch[\"Feature range(s)\"][0].split(\"-\")[0])-25,0)+50],class_weights,[batch[\"label\"]],device) # 三个序列和需要的突变采样位置，如突变从80号开始就是[80-25，80+25]\n",
    "            loss_onebatch = loss_onebatch + loss.item()\n",
    "        else:\n",
    "            positions = batch[\"position\"].tolist()\n",
    "            # print([sequence for sequence in batch[\"mut0\"]][0])\n",
    "            mut0,mut0_mask = esm_model.encode([sequence for sequence in batch[\"mut0\"]])\n",
    "            mut1,mut1_mask = esm_model.encode([sequence for sequence in batch[\"mut1\"]])\n",
    "            par0,par0_mask = esm_model.encode([sequence for sequence in batch[\"par0\"]])\n",
    "            #类似位置编码，标记突变前后的\n",
    "            zero_row = torch.zeros(mut0.shape[0], mut0.shape[1], 1).to(device)\n",
    "            mut0 = torch.cat((mut0, zero_row), dim=-1)\n",
    "            zero_row = torch.ones(mut1.shape[0], mut1.shape[1], 1).to(device)\n",
    "            mut1 = torch.cat((mut1, zero_row), dim=-1)\n",
    "            #处理mut0，mut1，去除0，找到位置，接入全局变量，01拼接在模型里\n",
    "            # mut0 = mut0[:, 1:, :]\n",
    "            if mut0.shape[1] < 2*len_half_protein_used:\n",
    "                mut0 = torch.cat((mut0.mean(dim=1, keepdim=True),mut0),dim=1)\n",
    "                mut0_mask = mut0_mask\n",
    "                mut1 = torch.cat((mut1.mean(dim=1, keepdim=True),mut1),dim=1)\n",
    "                mut1_mask = mut1_mask\n",
    "            else:\n",
    "                result = torch.randn(mut0.shape[0],2*len_half_protein_used,mut0.shape[2])\n",
    "                result_padding = (np.random.randint(0, 2, size=(mut0.shape[0], 2*len_half_protein_used)) == 1)\n",
    "\n",
    "                for ia in range(len(positions)):\n",
    "                    position = int(positions[ia])\n",
    "                    if position - len_half_protein_used < 0 :\n",
    "                        result[ia, :, :] = mut0[ia,:2 * len_half_protein_used,:]\n",
    "                        result_padding[ia, :] = mut0_mask[ia,1:1+2 * len_half_protein_used].cpu()\n",
    "                    elif position + len_half_protein_used > mut0.shape[1] - 1:\n",
    "                        result[ia, :, :] = mut0[ia,-2 * len_half_protein_used:,:]\n",
    "                        result_padding[ia, :] = mut0_mask[ia, -2 * len_half_protein_used].cpu()\n",
    "                    else:\n",
    "                        result[ia, :, :] = mut0[ia,position - len_half_protein_used:position + len_half_protein_used,:]\n",
    "                        result_padding[ia, :] = mut0_mask[ia,1+ position - len_half_protein_used:1 + position + len_half_protein_used].cpu()\n",
    "\n",
    "                mut0 = torch.cat((mut0.mean(dim=1, keepdim=True).cpu(), result),dim=1)\n",
    "                mut0_mask = result_padding\n",
    "                mut0_mask = np.concatenate([np.full((mut0_mask.shape[0], 1), False), mut0_mask], axis=1)\n",
    "                \n",
    "                \n",
    "                \n",
    "                result = torch.randn(mut1.shape[0],2*len_half_protein_used,mut1.shape[2])\n",
    "                result_padding = (np.random.randint(0, 2, size=(mut1.shape[0], 2*len_half_protein_used)) == 1)\n",
    "                for ia in range(len(positions)):\n",
    "                    position = int(positions[ia])\n",
    "                    if position - len_half_protein_used < 0 :\n",
    "                        result[ia, :, :] = mut1[ia,:2 * len_half_protein_used,:]\n",
    "                        result_padding[ia, :] = mut1_mask[ia,1:1+2 * len_half_protein_used].cpu()\n",
    "                    elif position + len_half_protein_used > mut1.shape[1] - 1:\n",
    "                        result[ia, :, :] = mut1[ia,-2 * len_half_protein_used : ,:]\n",
    "                        result_padding[ia, :] = mut1_mask[ia, -2 * len_half_protein_used].cpu()\n",
    "                    else:\n",
    "                        # print(i)\n",
    "                        result[ia, :, :] = mut1[ia,position - len_half_protein_used:position + len_half_protein_used,:]\n",
    "                        result_padding[ia, :] = mut1_mask[ia,1+ position - len_half_protein_used:1 + position + len_half_protein_used].cpu()\n",
    "                mut1 = torch.cat((mut1.mean(dim=1, keepdim=True).cpu(), result),dim=1)\n",
    "                mut1_mask = result_padding\n",
    "                mut1_mask = np.concatenate([np.full((mut1_mask.shape[0], 1), False), mut1_mask], axis=1)\n",
    "                \n",
    "                \n",
    "            mut0_mask = torch.from_numpy(mut0_mask)\n",
    "            mut0_mask = mut0_mask.to(device)\n",
    "            mut1_mask = torch.from_numpy(mut1_mask)\n",
    "            mut1_mask = mut1_mask.to(device)\n",
    "            mut0 = mut0.to(device)\n",
    "            mut1 = mut1.to(device)\n",
    "            par0 = par0.to(device)\n",
    "            # par0_mask = torch.from_numpy(par0_mask)\n",
    "            # for position in batch[\"Feature range(s)\"]:\n",
    "            #     positions.append([max(int(position[0].split(\"-\")[0])-25,0),max(int(position[0].split(\"-\")[0])-25,0)+50])\n",
    "            out = model(mut0, mut1, par0,mut0_mask,mut1_mask,par0_mask, class_weights,batch[\"label\"])\n",
    "            loss = model_loss(batch[\"label\"], out,class_weights)\n",
    "            _, predicted_labels = torch.max(out, 1)\n",
    "            # break\n",
    "            # loss = ghm_loss(out, batch[\"label\"].to_list())\n",
    "            # loss_onebatch = loss_onebatch + loss.item()\n",
    "            loss_range.append(loss.item())\n",
    "            # print(loss.item())\n",
    "            \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        print(\"done\")\n",
    "        label_need_train = label_need_train + batch[\"label\"].to_list()\n",
    "        label_pred_train = label_pred_train + predicted_labels.tolist()\n",
    "        if (i) % batch_size*20 == 0:\n",
    "            clear_output()\n",
    "            print(f' [{i}/{num_epochs}], Loss: {loss}')\n",
    "\n",
    "        i = i+batch_size\n",
    "    accuracy = accuracy_score(label_need_train,label_pred_train)\n",
    "    acc_train.append(accuracy)\n",
    "    torch.save(model.state_dict(), 'model_params_copy3.pth')\n",
    "    model.eval()\n",
    "    data_reader = PandasDataReader(x_test_fold, batch_size=10, shuffle=True)\n",
    "    num_epochs = len(x_train_fold)\n",
    "    print(\"testing\",epoc)\n",
    "    for batch in data_reader:\n",
    "        if False:\n",
    "            loss = model([batch[\"mut0\"]],[ batch[\"mut1\"]], [batch[\"par0\"]], [max(int(batch[\"Feature range(s)\"][0].split(\"-\")[0])-25,0),max(int(batch[\"Feature range(s)\"][0].split(\"-\")[0])-25,0)+50],class_weights,[batch[\"label\"]],device) # 三个序列和需要的突变采样位置，如突变从80号开始就是[80-25，80+25]\n",
    "            loss_onebatch = loss_onebatch + loss.item()\n",
    "        else:\n",
    "            positions = batch[\"position\"].tolist()\n",
    "            # print([sequence for sequence in batch[\"mut0\"]][0])\n",
    "            mut0,mut0_mask = esm_model.encode([sequence for sequence in batch[\"mut0\"]])\n",
    "            mut1,mut1_mask = esm_model.encode([sequence for sequence in batch[\"mut1\"]])\n",
    "            par0,par0_mask = esm_model.encode([sequence for sequence in batch[\"par0\"]])\n",
    "            zero_row = torch.zeros(mut0.shape[0], mut0.shape[1], 1).to(device)\n",
    "            mut0 = torch.cat((mut0, zero_row), dim=-1)\n",
    "            zero_row = torch.ones(mut1.shape[0], mut1.shape[1], 1).to(device)\n",
    "            mut1 = torch.cat((mut1, zero_row), dim=-1)\n",
    "            #处理mut0，mut1，去除0，找到位置，接入全局变量，01拼接在模型里\n",
    "            # mut0 = mut0[:, 1:, :]\n",
    "            if mut0.shape[1] < 2*len_half_protein_used:\n",
    "                mut0 = torch.cat((mut0.mean(dim=1, keepdim=True),mut0),dim=1)\n",
    "                mut0_mask = mut0_mask\n",
    "                mut1 = torch.cat((mut1.mean(dim=1, keepdim=True),mut1),dim=1)\n",
    "                mut1_mask = mut1_mask\n",
    "            else:\n",
    "                result = torch.randn(mut0.shape[0],2*len_half_protein_used,mut0.shape[2])\n",
    "                result_padding = (np.random.randint(0, 2, size=(mut0.shape[0], 2*len_half_protein_used)) == 1)\n",
    "\n",
    "                for ia in range(len(positions)):\n",
    "                    position = int(positions[ia])\n",
    "                    if position - len_half_protein_used < 0 :\n",
    "                        result[ia, :, :] = mut0[ia,:2 * len_half_protein_used,:]\n",
    "                        result_padding[ia, :] = mut0_mask[ia,1:1+2 * len_half_protein_used].cpu()\n",
    "                    elif position + len_half_protein_used > mut0.shape[1] - 1:\n",
    "                        result[ia, :, :] = mut0[ia,-2 * len_half_protein_used:,:]\n",
    "                        result_padding[ia, :] = mut0_mask[ia, -2 * len_half_protein_used].cpu()\n",
    "                    else:\n",
    "                        result[ia, :, :] = mut0[ia,position - len_half_protein_used:position + len_half_protein_used,:]\n",
    "                        result_padding[ia, :] = mut0_mask[ia,1+ position - len_half_protein_used:1 + position + len_half_protein_used].cpu()\n",
    "\n",
    "                mut0 = torch.cat((mut0.mean(dim=1, keepdim=True).cpu(), result),dim=1)\n",
    "                mut0_mask = result_padding\n",
    "                mut0_mask = np.concatenate([np.full((mut0_mask.shape[0], 1), False), mut0_mask], axis=1)\n",
    "                \n",
    "                \n",
    "                \n",
    "                result = torch.randn(mut1.shape[0],2*len_half_protein_used,mut1.shape[2])\n",
    "                result_padding = (np.random.randint(0, 2, size=(mut1.shape[0], 2*len_half_protein_used)) == 1)\n",
    "                for ia in range(len(positions)):\n",
    "                    position = int(positions[ia])\n",
    "                    if position - len_half_protein_used < 0 :\n",
    "                        result[ia, :, :] = mut1[ia,:2 * len_half_protein_used,:]\n",
    "                        result_padding[ia, :] = mut1_mask[ia,1:1+2 * len_half_protein_used].cpu()\n",
    "                    elif position + len_half_protein_used > mut1.shape[1] - 1:\n",
    "                        result[ia, :, :] = mut1[ia,-2 * len_half_protein_used : ,:]\n",
    "                        result_padding[ia, :] = mut1_mask[ia, -2 * len_half_protein_used].cpu()\n",
    "                    else:\n",
    "                        # print(i)\n",
    "                        result[ia, :, :] = mut1[ia,position - len_half_protein_used:position + len_half_protein_used,:]\n",
    "                        result_padding[ia, :] = mut1_mask[ia,1+ position - len_half_protein_used:1 + position + len_half_protein_used].cpu()\n",
    "                mut1 = torch.cat((mut1.mean(dim=1, keepdim=True).cpu(), result),dim=1)\n",
    "                mut1_mask = result_padding\n",
    "                mut1_mask = np.concatenate([np.full((mut1_mask.shape[0], 1), False), mut1_mask], axis=1)\n",
    "                \n",
    "                \n",
    "            mut0_mask = torch.from_numpy(mut0_mask)\n",
    "            mut0_mask = mut0_mask.to(device)\n",
    "            mut1_mask = torch.from_numpy(mut1_mask)\n",
    "            mut1_mask = mut1_mask.to(device)\n",
    "            mut0 = mut0.to(device)\n",
    "            mut1 = mut1.to(device)\n",
    "            par0 = par0.to(device)\n",
    "            x = model(mut0, mut1, par0, mut0_mask, mut1_mask, par0_mask, class_weights,batch[\"label\"])\n",
    "            _, predicted = torch.max(x, 1)\n",
    "            label_pred = label_pred + predicted.tolist()\n",
    "            label_need = label_need + batch['label'].to_list()\n",
    "    accuracy = accuracy_score(label_need, label_pred)\n",
    "    acc_test.append(accuracy)\n",
    "    model.train()\n",
    "    with open('test_result_copy3.json', 'w') as file:\n",
    "        json.dump(acc_test, file)\n",
    "    with open('train_result_copy3.json', 'w') as file:\n",
    "        json.dump(acc_train, file)\n",
    "    if accuracy > 0.8:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0d3610-178f-4d81-9dee-90e44b70afe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.48628409872392453,\n",
       " 0.5138305188354856,\n",
       " 0.5331244746695194,\n",
       " 0.5493237563994804,\n",
       " 0.5608619240467639,\n",
       " 0.5689997707648812,\n",
       " 0.5754183540918468,\n",
       " 0.5846259646977917,\n",
       " 0.589439902193016,\n",
       " 0.5960113089325285,\n",
       " 0.6052953312447467,\n",
       " 0.6082371819362726,\n",
       " 0.6088102697333232,\n",
       " 0.6125544433407198,\n",
       " 0.6195079086115993,\n",
       " 0.6211507602964774,\n",
       " 0.6237105524566363,\n",
       " 0.55639183922977,\n",
       " 0.569916711240162,\n",
       " 0.5816841140062657,\n",
       " 0.5905478719339803,\n",
       " 0.5988385420646443,\n",
       " 0.6060594483074807,\n",
       " 0.6070528004890349,\n",
       " 0.6154198823259723,\n",
       " 0.6173301749828074,\n",
       " 0.6209215251776572,\n",
       " 0.6253534041415145,\n",
       " 0.629747077252235,\n",
       " 0.6320776342935738,\n",
       " 0.6333766333002216,\n",
       " 0.637541071292122,\n",
       " 0.6381141590891725,\n",
       " 0.6420875678153893,\n",
       " 0.6455260945976924,\n",
       " 0.6393749522426836,\n",
       " 0.6481622984641247,\n",
       " 0.6531672652250324,\n",
       " 0.6562619393291053,\n",
       " 0.6551157637350042,\n",
       " 0.659089172461221,\n",
       " 0.6793764804768091,\n",
       " 0.7013448460304118,\n",
       " 0.7086803698326584,\n",
       " 0.7199510965079851,\n",
       " 0.7296553832047069,\n",
       " 0.7376022006571407,\n",
       " 0.749675250248338,\n",
       " 0.7565905096660809,\n",
       " 0.7566287155192175,\n",
       " 0.7556353633376633,\n",
       " 0.7641170627340108,\n",
       " 0.7654542675937954,\n",
       " 0.762321387636586,\n",
       " 0.7602964774203408,\n",
       " 0.7662947963628027]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd74876-5560-4d73-9679-a0ca2ceabd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4bce20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "def print_progress_bar(iteration, total, length=40):\n",
    "    percent = (iteration / total) * 100\n",
    "    filled_length = int(length * iteration // total)\n",
    "    bar = '█' * filled_length + '-' * (length - filled_length)\n",
    "    sys.stdout.write(f'\\r|{bar}| {percent:.2f}% Complete')\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2137c7-6fd6-45fd-9508-08d0f52d27e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|████████████████████████████████████████| 100.00% Complete"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "data_reader = PandasDataReader(x_test_fold, batch_size=10, shuffle=True)\n",
    "num_epochs = len(x_train_fold)\n",
    "print(\"testing\",epoc)\n",
    "for batch in data_reader:\n",
    "    if False:\n",
    "        loss = model([batch[\"mut0\"]],[ batch[\"mut1\"]], [batch[\"par0\"]], [max(int(batch[\"Feature range(s)\"][0].split(\"-\")[0])-25,0),max(int(batch[\"Feature range(s)\"][0].split(\"-\")[0])-25,0)+50],class_weights,[batch[\"label\"]],device) # 三个序列和需要的突变采样位置，如突变从80号开始就是[80-25，80+25]\n",
    "        loss_onebatch = loss_onebatch + loss.item()\n",
    "    else:\n",
    "        positions = batch[\"position\"].tolist()\n",
    "        # print([sequence for sequence in batch[\"mut0\"]][0])\n",
    "        mut0,mut0_mask = esm_model.encode([sequence for sequence in batch[\"mut0\"]])\n",
    "        mut1,mut1_mask = esm_model.encode([sequence for sequence in batch[\"mut1\"]])\n",
    "        par0,par0_mask = esm_model.encode([sequence for sequence in batch[\"par0\"]])\n",
    "        # zero_row = torch.zeros(mut0.shape[0], mut0.shape[1], 1).to(device)\n",
    "        # mut0 = torch.cat((mut0, zero_row), dim=-1)\n",
    "        # zero_row = torch.ones(mut1.shape[0], mut1.shape[1], 1).to(device)\n",
    "        # mut1 = torch.cat((mut1, zero_row), dim=-1)\n",
    "        #处理mut0，mut1，去除0，找到位置，接入全局变量，01拼接在模型里\n",
    "        # mut0 = mut0[:, 1:, :]\n",
    "        if mut0.shape[1] < 2*len_half_protein_used:\n",
    "            mut0 = torch.cat((mut0.mean(dim=1, keepdim=True),mut0),dim=1)\n",
    "            mut0_mask = mut0_mask\n",
    "            mut1 = torch.cat((mut1.mean(dim=1, keepdim=True),mut1),dim=1)\n",
    "            mut1_mask = mut1_mask\n",
    "        else:\n",
    "            result = torch.randn(mut0.shape[0],2*len_half_protein_used,mut0.shape[2])\n",
    "            result_padding = (np.random.randint(0, 2, size=(mut0.shape[0], 2*len_half_protein_used)) == 1)\n",
    "\n",
    "            for ia in range(len(positions)):\n",
    "                position = int(positions[ia])\n",
    "                if position - len_half_protein_used < 0 :\n",
    "                    result[ia, :, :] = mut0[ia,:2 * len_half_protein_used,:]\n",
    "                    result_padding[ia, :] = mut0_mask[ia, : 2 * len_half_protein_used].cpu()\n",
    "                elif position + len_half_protein_used > mut0.shape[1] :\n",
    "                    result[ia, :, :] = mut0[ia,-2 * len_half_protein_used:,:]\n",
    "                    result_padding[ia, :] = mut0_mask[ia, -2 * len_half_protein_used].cpu()\n",
    "                else:\n",
    "                    result[ia, :, :] = mut0[ia,position - len_half_protein_used:position + len_half_protein_used,:]\n",
    "                    result_padding[ia, :] = mut0_mask[ia, position - len_half_protein_used : position + len_half_protein_used].cpu()\n",
    "\n",
    "            mut0 = torch.cat((mut0.mean(dim=1, keepdim=True).cpu(), result),dim=1)\n",
    "            mut0_mask = result_padding\n",
    "            mut0_mask = np.concatenate([np.full((mut0_mask.shape[0], 1), False), mut0_mask], axis=1)\n",
    "            \n",
    "            \n",
    "            \n",
    "            result = torch.randn(mut1.shape[0],2*len_half_protein_used,mut1.shape[2])\n",
    "            result_padding = (np.random.randint(0, 2, size=(mut1.shape[0], 2*len_half_protein_used)) == 1)\n",
    "            for ia in range(len(positions)):\n",
    "                position = int(positions[ia])\n",
    "                if position - len_half_protein_used < 0 :\n",
    "                    result[ia, :, :] = mut1[ia,:2 * len_half_protein_used,:]\n",
    "                    result_padding[ia, :] = mut1_mask[ia , : 2 * len_half_protein_used].cpu()\n",
    "                elif position + len_half_protein_used > mut1.shape[1] :\n",
    "                    result[ia, :, :] = mut1[ia,-2 * len_half_protein_used : ,:]\n",
    "                    result_padding[ia, :] = mut1_mask[ia , -2 * len_half_protein_used].cpu()\n",
    "                else:\n",
    "                    # print(i)\n",
    "                    result[ia, :, :] = mut1[ia,position - len_half_protein_used:position + len_half_protein_used,:]\n",
    "                    result_padding[ia, :] = mut1_mask[ia, position - len_half_protein_used : position + len_half_protein_used].cpu()\n",
    "            mut1 = torch.cat((mut1.mean(dim=1, keepdim=True).cpu(), result),dim=1)\n",
    "            mut1_mask = result_padding\n",
    "            mut1_mask = np.concatenate([np.full((mut1_mask.shape[0], 1), False), mut1_mask], axis=1)\n",
    "            \n",
    "            \n",
    "        mut0_mask = torch.from_numpy(mut0_mask)\n",
    "        mut0_mask = mut0_mask.to(device)\n",
    "        mut1_mask = torch.from_numpy(mut1_mask)\n",
    "        mut1_mask = mut1_mask.to(device)\n",
    "        mut0 = mut0.to(device)\n",
    "        mut1 = mut1.to(device)\n",
    "        par0 = par0.to(device)\n",
    "        mut0 = mut0 + position_embedding[:mut0.shape[1] , : ]\n",
    "        mut1 = mut1 + position_embedding[2 * len_half_protein_used + 1 : 2 * len_half_protein_used + 1 + mut1.shape[1] , : ]\n",
    "        x = model(mut0, mut1, par0, mut0_mask,mut1_mask, par0_mask, class_weights,batch[\"label\"])\n",
    "        _, predicted = torch.max(x, 1)\n",
    "        label_pred = label_pred + predicted.tolist()\n",
    "        label_need = label_need + batch['label'].to_list()\n",
    "# accuracy = accuracy_score(label_need, label_pred)\n",
    "# acc_test.append(accuracy)\n",
    "# model.train()\n",
    "    print_progress_bar(len(label_need), x_test_fold.shape[0], length=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88368004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision  recall  f1-score   support\n",
      "Disrupting       0.6536  0.6803    0.6667  635.0000\n",
      "Decreasing       0.5160  0.3899    0.4442  495.0000\n",
      "No effect        0.8661  0.9127    0.8888 1283.0000\n",
      "Increasing       0.5854  0.6162    0.6004  495.0000\n",
      "accuracy         0.7225  0.7225    0.7225    0.7225\n",
      "macro avg        0.6553  0.6498    0.6500 2908.0000\n",
      "weighted avg     0.7123  0.7225    0.7155 2908.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report_df = classification_report(label_need, label_pred, target_names=['Disrupting', 'Decreasing', 'No effect', 'Increasing'], output_dict=True)\n",
    "report_df = pd.DataFrame(report_df).transpose()\n",
    "\n",
    "# 设置小数位数\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "\n",
    "# 打印格式化后的报告\n",
    "print(report_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ddaa1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_params_withoutcross.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c689e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_params_copy3.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553cecf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('label_need_withoutcross.json', 'w') as file:\n",
    "    json.dump(label_need, file)\n",
    "with open('label_pred_withoutcross.json', 'w') as file:\n",
    "    json.dump(label_pred, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
